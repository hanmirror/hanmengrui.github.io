<!DOCTYPE html>
<!-- saved from url=(0048)https://groups.csail.mit.edu/vision/torralbalab/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
   <meta name="author" content="Aina Torralba">
  
  <title>Antonio Torralba</title>

  <!-- Bootstrap core CSS -->
  <link href="./Antonio Torralba_files/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="./Antonio Torralba_files/scrolling-nav.css" rel="stylesheet">
  <link href="./Antonio Torralba_files/styles.css" rel="stylesheet">
</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-at fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand home-link js-scroll-trigger" href="https://groups.csail.mit.edu/vision/torralbalab/#page-top">Antonio Torralba</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="https://groups.csail.mit.edu/vision/torralbalab/#members">Lab Members</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="https://groups.csail.mit.edu/vision/torralbalab/#research">Research</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="https://groups.csail.mit.edu/vision/torralbalab/#news">News</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="https://groups.csail.mit.edu/vision/torralbalab/#datasets">Datasets</a>
          </li>
           <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="https://groups.csail.mit.edu/vision/torralbalab/#publications">Publications</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="https://groups.csail.mit.edu/vision/torralbalab/#gallery">Gallery</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="https://accessibility.mit.edu/">Accessibility</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>


  <div id="container">
        <div id="main">
          <div id="pic">
              <img src="./Antonio Torralba_files/antonioTorralbaS.jpg" width="200" height="200">
            </div>
            <div id="department">
              <h1>Antonio Torralba</h1>
                  <p class="note">Delta Electronics Professor of Electrical Engineering and Computer Science.</p>
                  <p class="note">Head AI+D faculty, EECS dept. (<a href="http://news.mit.edu/2019/restructuring-mit-department-electrical-engineering-computer-science-1205">link</a>)
                  <br>                    
                  </p><p> Computer Science and Artificial Intelligence Laboratory
                       - Dept. of Electrical Engineering and Computer Science<br>
                      <b>Massachusetts Institute of Technology</b>
                  </p>
                  <p>Office: 32-386G<br>
                  32 Vassar Street,
                  Cambridge, MA 02139<br>
                  Email: torralba@mit.edu<br>
                  Assistant: <a href="http://web.mit.edu/fernd/www/">Fern DeOliveira Keniston</a>
                  </p>
            </div>
            <div id="intro">
              <p>My research is in the areas of computer vision, machine learning and human visual perception. I am interested in building
                systems that can perceive the world like humans do. Although my work focuses on computer vision I am also interested in other modalities such as audition and touch. A system able to perceive the world through multiple senses might be able to learn without requiring massive curated datasets. Other interests include understanding neural networks, common-sense reasoning, computational photography, building image databases, ..., and the intersections between visual art and computation.</p>
            </div> 
        </div>

  <!---------------------------------- LAB MEMBERS ------------------------------------- -->
        <div id="members">
            <h2>Lab Members</h2>
            <div id="columnswrapper">

<!--              <div class="columnmembers">
                <div id="pic_members"><img src="assets/images/people/dimpapadopoulos.jpg" width="128" height="128"/>
                </div>
                <p><a href="https://scholar.google.com/citations?user=-_JAhdQAAAAJ&hl=en">Dim P. Papadopoulos</a> <br> Postdoc</p>
              </div>-->

<!--              <div class="columnmembers">
                <div id="pic_members"><img src="assets/images/people/jonaswulff.png" width="128" height="128"/></div>
                <p>
                <a href="http://people.csail.mit.edu/jwulff/">Jonas Wulff</a> <br>Postdoc</p>
              </div>-->


           <div class="columnmembers">
            <div id="pic_members">
                <img src="./Antonio Torralba_files/chuang.jpg" width="128" height="128">
            </div>
            <p><a href="http://people.csail.mit.edu/ganchuang/">Chuang Gan</a><br>IBM Researcher</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/james.jpg" width="128" height="128">
              </div>
              <p><a href="https://chingyaoc.github.io/">Ching-Yao Chuang</a> <br>Grad Student</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/davidbau.jpg" width="128" height="128">
              </div>
              <p> <a href="http://people.csail.mit.edu/davidbau/home/">David Bau</a> <br>Grad Student</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
            	<img src="./Antonio Torralba_files/joanna.jpg" width="128" height="128">
              </div>
              <p> <a href="https://joaanna.github.io/">Joanna Materzynska</a> <br>Grad Student</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/manel.jpg" width="128" height="128">
              </div>
              <p><a href="https://mbaradad.github.io/">Manel Baradad</a> <br>Grad Student</p>
            </div>
            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/nadiia.jpg" width="128" height="128">
              </div>
              <p> <a href="https://dblp.uni-trier.de/pid/236/5817.html">Nadiia Chepurko</a> <br>Grad Student</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/pratyusha.jpg" width="128" height="128">
              </div>
              <p><a href="https://scholar.google.co.in/citations?user=RGiCLUgAAAAJ&amp;hl=en">Pratyusha Sharma</a> <br>Grad Student</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/sarah.jpg" width="128" height="128">
              </div>
              <p><a href="http://www.cogconfluence.com/">Sarah Schwettmann</a> <br>Postdoc</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/ShuangLi.jpg" width="128" height="128">
              </div>
              <p><a href="http://www.mit.edu/~lishuang/">Shuang Li</a> <br>Grad Student</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/tianmin_shu.jpg" width="128" height="128">
              </div>
              <p><a href="https://www.tshu.io/">Tianmin Shu</a> <br>Postdoc</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/TongzhouWang.jpg" width="128" height="128">
              </div>
              <p><a href="https://ssnl.github.io/">Tongzhou Wang</a><br>Grad Student</p>
            </div>

           <div class="columnmembers">
            <div id="pic_members">
              <img src="./Antonio Torralba_files/Wei-Chiu-Ma.jpg" width="128" height="128">
            </div>
            <p><a href="http://people.csail.mit.edu/weichium/">Wei-Chiu Ma</a><br>Grad Student</p>
            </div>
            
            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/xavi.jpg" width="128" height="128">
              </div>
              <p><a href="http://people.csail.mit.edu/xavierpuig/">Xavier Puig Fernandez</a> <br>Grad Student</p>
            </div>

            <div class="columnmembers">
              <div id="pic_members">
                <img src="./Antonio Torralba_files/yunzhuli.jpg" width="128" height="128">
              </div>
              <p><a href="http://people.csail.mit.edu/liyunzhu/">Yunzhu Li</a> <br>Grad Student</p>
            </div>

<!--            <div class="columnmembers">
              <div id="pic_members">
                <img src="assets/images/people/EthanWeber.jpg" width="128" height="128"/>
              </div>
              <p><a href="https://ethanweber.me/">Ethan Weber</a> <br>MEng Student</p>
            </div>-->

 <!--           <div class="columnmembers">
              <div id="pic_members">
                <img src="assets/images/people/JingweiMa.jpg" width="128" height="128"/>
              </div>
              <p><a href="https://jma100.github.io/">Jingwei Ma</a> <br>MEng Student</p>
            </div>-->

 <!--           <div class="columnmembers">
              <div id="pic_members">
                <img src="assets/images/people/MahiElango.jpg" width="128" height="128"/>
              </div>
              <p>Mahi Elango</a> <br>MEng Student</p>
            </div>-->

<!--            <div class="columnmembers">
              <div id="pic_members">
                <img src="assets/images/people/ChristineYejinYou.jpg" width="128" height="128"/>
              </div>
              <p>Christine Yejin You</a> <br>MEng Student</p>
            </div>-->

<!--
            <div class="columnmembers">
              <div id="pic_members">
                <img src="assets/images/people/IoannisKaklamanis.jpg" width="128" height="128"/>
              </div>
              <p>Ioannis Kaklamanis</a> <br>UROP Student</p>
            </div>
-->
<!--            <div class="columnmembers">
              <div id="pic_members">
                <img src="assets/images/people/SamBoshar.jpg" width="128" height="128"/>
              </div>
              <p>Sam Boshar</a> <br>UROP Student</p>
            </div>-->
<!--

             <div class="columnmembers">
              <div id="pic_members">
                <img src="assets/images/people/BernatFelip.jpg" width="128" height="128"/>
              </div>
              <p><a href="https://sirbernardphilip.github.io/">Bernat Felip i Diaz</a> <br>Visiting Student</p>
            </div>
-->
<!--            <div class="columnmembers">
              <div id="pic_members">
                <img src="assets/images/people/MireiaHernandez.jpg" width="128" height="128"/>
              </div>
              <p><a href="https://github.com/mireiahernandez">Mireia Hernandez Caralt</a> <br>Visiting Student</p>
            </div>-->

           
   </div>
   <div id="members2">
            <h3>Past Students and Postdocs</h3>
            <p>
            <a href="http://people.csail.mit.edu/recasens/">Adrià Recasens</a> (Graduated 2019),
            <a href="http://people.csail.mit.edu/hangzhao/">Hang Zhao</a> (Graduated 2019),
            <a href="https://people.csail.mit.edu/junyanz/">Jun-Yan Zhu</a> (Postdoc),
            <a href="http://people.csail.mit.edu/bzhou">Bolei Zhou</a> (Graduated 2018),
            <a href="http://mit.edu/vondrick/">Carl Vondrick</a> (Graduated 2017),
            <a href="http://people.csail.mit.edu/jmarin/">Javier Marin</a> (Postdoc),
            <a href="http://people.csail.mit.edu/yusuf/">Yusuf Aytar</a> (Postdoc)
            <a href="http://people.csail.mit.edu/aho/">Andrew Owens </a> (Graduated 2016),
            <a href="http://people.csail.mit.edu/khosla/">Aditya Khosla</a> (Graduated 2016),
            <a href="http://sunai.uoc.edu/~agata/">Agata Lapedriza </a> (Visiting professor, UOC),
            <a href="http://people.csail.mit.edu/lim/">Joseph J. Lim </a>(Graduated 2015),
            <a href="http://www.lluiscastrejon.com/">Lluis Castrejon</a> (Visiting student, 2015),
            <a href="http://www.ics.uci.edu/~hpirsiav/">Hamed Pirsiavash</a> (Postdoc),
            <a href="http://web.mit.edu/zoya/www/index.html">Zoya Gavrilov</a> (Grad. Student).
            <a href="https://groups.csail.mit.edu/vision/torralbalab/">Josep Marc Mingot Hidalgo</a> (Visiting student),
            <a href="http://people.csail.mit.edu/tomasz/index.html">Tomasz Malisiewicz</a> (Postdoc),
            <a href="http://vision.princeton.edu/people/xj/">Jianxiong Xiao </a> (Graduated 2013),
            <a href="https://groups.csail.mit.edu/vision/torralbalab/">Dolores Blanco Almazan</a> (Visiting student, 2012),
            <a href="http://people.csail.mit.edu/biliana/">Biliana Kaneva</a> (Graduated 2011),
            <a href="http://people.csail.mit.edu/jenny/">Jenny Yuen</a> (Graduated 2011),
            <a href="http://people.csail.mit.edu/tjudd//">Tilke Judd</a> (Graduated 2011)
            <a href="http://www.mit.edu/~myungjin/">Myung "Jin" Choi</a> (Graduated 2011),
            <a href="http://www.cs.cmu.edu/~jhhays/">James Hays</a> (Postdoc),
            <a href="http://www.etsetb.upc.es/">Hector J.Bernal</a> (Visiting student),
            <a href="http://www.cs.cmu.edu/~gunhee/">Gunhee Kim</a> (Visiting student),
            <a href="http://www.cs.washington.edu/homes/bcr/">Bryan C. Russell</a> (Graduated 2008).
            </p>
          </div>

        </div>

  <!---------------------------------- RESEARCH ------------------------------------- -->       
        <div id="research" class="thumbs-section">
            <h2>Research</h2>
            <p>It is all about context!</p> 


            <p><img src="./Antonio Torralba_files/sunicon.jpg" width="64" height="64">Scene understanding and context driven object recognition.
            </p>

            <p><img src="./Antonio Torralba_files/auditorysceneanalysis.png" width="64" height="64">Integration of vision, audition and touch (and smell!): perceiving the world via multiple senses. I would like to study computer vision in the context of other perceptual modalities. <!--<a href="https://projects.csail.mit.edu/soundnet/">Auditory scene analysis</a>: using vision to teach audition. <a href="http://web.mit.edu/vondrick/soundnet.pdf">NIPS paper</a> by Yusuf and Carl. Check also Andrew's <a href="https://arxiv.org/pdf/1608.07017.pdf">ECCV paper</a> on using audition to teach vision.-->
            </p>

            <p><img src="./Antonio Torralba_files/objects.gif" width="64" height="64">Building datasets: AI is an empirical science. Measuring the world is an important part of asking questions about perception and building perceptual models. I am interested in building datasets with complex scenes, with objects in context and multiple perceptual modalities.
            </p>

            <p><img src="./Antonio Torralba_files/ganpaint2.gif" width="64" height="64">Dissecting neural networks: visualization and interpretation of the representation learned by neural networks. <a href="http://gandissect.csail.mit.edu/">GAN dissection</a> and <a href="http://netdissect.csail.mit.edu/"> Network dissection</a>.
            </p>


        </div>



 <!---------------------------------- NEWS ------------------------------------- -->
       <div id="news" class="thumbs-section">
         
          <h2>News</h2>

            <p><img src="./Antonio Torralba_files/eecs.jpg" width="64" height="64">2020 - <a href="http://news.mit.edu/2019/restructuring-mit-department-electrical-engineering-computer-science-1205">Named the head of the faculty of artificial intelligence and decision-making (AI+D)</a>. AI+D is a new unit within EECS, which brings together machine learning, AI and decision making, while keeping strong connections with its roots in EE and CS. This unit focuses on faculty recruiting, mentoring, promotion, academic programs, and community building.  
            </p>

            <p><img src="./Antonio Torralba_files/mit.png" width="64" height="64">2018 - 2020 <a href="http://news.mit.edu/2018/mit-announces-leadership-quest-intelligence-0611">MIT Quest for intelligence</a>: I have been named inaugural director of the MIT Quest for Intelligence. The Quest is a campus-wide initiative to discover the foundations of intelligence and to drive the development of technological tools that can positively influence virtually every aspect of society.
            </p>

            <p><img src="./Antonio Torralba_files/mitibmwatsonailab.jpg" width="64" height="64">2017 - 2020 <a href="http://news.mit.edu/2017/new-leadership-for-mit-ibm-watson-ai-lab-antonio-torralba-0920">MIT IBM Watson AI lab</a>: named the MIT director of the MIT IBM Watson AI lab.
            </p>
            <p></p>
        

 <!----------------------------------COOL  NEWS ------------------------------------- -->
         <div>
            <h2>Cool news</h2>
            <p><img src="./Antonio Torralba_files/colbert.jpg" width="64" height="64"><a href="https://www.facebook.com/colbertlateshow/videos/889597367851682/?pnref=story">Late show with Stephen Colbert</a> on the work by Carl and Hamed, <a href="http://web.mit.edu/vondrick/prediction.pdf">Anticipating Visual Representations from Unlabeled Video.</a> CVPR 2016.
            </p>

            <p><img src="./Antonio Torralba_files/bbc.jpg" width="64" height="64">The <a href="https://www.youtube.com/watch?v=OlumoQ05gS8">Marilyn Monroe/Albert Einstein hybrid image</a> by Aude Oliva on BBC.
            </p>

            <p><img src="./Antonio Torralba_files/german.jpg" width="64" height="64">German TV science show on <a href="http://www.wdr.de/tv/kopfball/sendungsbeitraege/2014/0927/camera.jsp">accidental cameras</a>. Details about accidental cameras and some of our videos are available <a href="http://people.csail.mit.edu/torralba/research/accidentalcameras/">here</a>.
            </p>
          <br>
        </div>
</div>
 <!----------------------------------DATASETS ------------------------------------- -->        
        <div id="datasets" class="thumbs-section">
            <h2>Datasets</h2>
 
            <p><img src="./Antonio Torralba_files/virtualhome.jpg" width="64" height="64"><a href="http://virtual-home.org/">Virtual Home</a> (2019). VirtualHome is a platform to simulate complex household activities via programs. Key aspect of VirtualHome is that it allows complex interactions with the environment, such as picking up objects, switching on/off appliances, opening appliances, etc. Our simulator can easily be called with a Python API: write the activity as a simple sequence of instructions which then get rendered in VirtualHome. You can choose between different agents and environments, as well as modify environments on the fly. You can also stream different ground-truth such as time-stamped actions, instance/semantic segmentation, and optical flow and depth. Check out more details of the environment and platform in www.virtual-home.org. 
            </p>

            <p><img src="./Antonio Torralba_files/gaze.png" width="64" height="64"> <a href="http://gaze360.csail.mit.edu/">Gaze 360</a> (2019). Understanding where people are looking is an informative social cue that machines need to understand to interact with humans. In this work, we present Gaze360, a large-scale gaze-tracking dataset and method for robust 3D gaze estimation in unconstrained images. Our dataset consists of 238 participants in indoor and outdoor environments with labelled 3D gaze across a wide range of head poses and distances. 
            </p>

  
            <p><img src="./Antonio Torralba_files/art1162.jpg" width="64" height="64"> <a href="https://groups.csail.mit.edu/sls/downloads/placesaudio/index.cgi">The Places Audio Caption Corpus</a> (2018). The Places Audio Caption 400K Corpus contains approximately 400,000 spoken captions for natural images drawn from the Places 205 image dataset. It was collected to investigate multimodal learning schemes for unsupervised co-discovery of speech patterns and visual objects.
            </p>

            <p><img src="./Antonio Torralba_files/ade20k.jpg" width="64" height="64"><a href="http://groups.csail.mit.edu/vision/datasets/ADE20K/">ADE20K dataset</a> (2017). 22.210 fully annotated images with over 430.000 object instances and 175.000 parts. All images are fully segmented with over 3000 object and part categories. A reduced version of the dataset is used for the <a href="http://sceneparsing.csail.mit.edu/">scene parsing challenge</a>.
            </p> 

           <p><img src="./Antonio Torralba_files/places.jpg" width="64" height="64"> <a href="http://places2.csail.mit.edu/">Places database</a> (2017). The database contains more than 10 million images comprising 400+ scene categories. The dataset features 5000 to 30,000 training images per class. More details appear in: "Learning Deep Features for Scene Recognition using Places Database," B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva. NIPS 2014 (<a href="http://places.csail.mit.edu/places_NIPS14.pdf">pdf</a>). The Places database has two releases: Places <a href="http://places.csail.mit.edu/">release 1</a>, contains 205 scene categories and 2,5 million of images. Places <a href="http://places2.csail.mit.edu/">release 2</a>, contains 400 scene categories and 10 million of images. Pre-trained models available <a href="https://github.com/CSAILVision/places365">here</a>.
           </p>


            <p><img src="./Antonio Torralba_files/cmplaces.png" width="64" height="64"><a href="http://projects.csail.mit.edu/cmplaces/">CMPlaces</a> (2016). CMPlaces is designed to train and evaluate cross-modal scene recognition models. It covers five different modalities: natural images, sketches, clip-art, text descriptions, and spatial text images. The dataset is organized with the same categories as the <a href="http://places.csail.mit.edu/">Places database</a>. More details in <a href="http://cmplaces.csail.mit.edu/content/paper_pami.pdf">paper.pdf</a> 
            </p>    

                 
<!--             <p><img src="assets/images/ikea.png" width="64" height="64"/><a href="http://ikea.csail.mit.edu/">
             3D IKEA dataset</a> (2013). In order to develop and evaluate fine pose estimation based on 3D models, we created a new dataset of images and 3D models representing typical indoor scenes. We collected IKEA 3D models from Google 3D Warehouse, and images from Flickr. This dataset contains about 759 images and 219 3D-models. All 759 images are annotated using available models (about 90 different models). Also, we separate the data into two different splits: IKEAobject and IKEAroom.
             </p>-->
<!--
            <p><img src="assets/images/sun360.jpg" width="64" height="64"/><a href="http://3dvision.princeton.edu/projects/2012/SUN360/">360-SUN Database</a> (2012). A database of 360 degrees panoramas organized along the SUN categories. The pose of an object carries crucial semantic meaning for object manipulation and usage (e.g., grabbing a mug, watching a television). Just as pose estimation is part of object recognition, viewpoint recognition is an important component of scene recognition. For instance, a theater has a clear distinct distributions of objects – a stage on one side and seats on the other – that deﬁnes unique views in different orientations. The goal of this dataset was to study the viewpoint recognition problem in scenes.
            </p>    
                   -->
                         
            <p><img src="./Antonio Torralba_files/outofcontext.jpg" width="64" height="64"> <a href="http://people.csail.mit.edu/torralba/research/out_of_context/out_of_context.zip">Out of context objects</a> (2012). The database contains 218 fully annotated images with at least one object out-of-context. Context models have been evaluated mostly based on the improvement of object recognition performance even though it is only one of many ways to exploit contextual information. Can you detect the out of context object? Detecting “out-of-context” objects and scenes is challenging because context violations can be detected only if the relationships between objects are carefully and precisely modeled. <a href="http://people.csail.mit.edu/myungjin/outOfContext.html">Project page</a>
            </p>

 <!--           <p><img src="assets/images/indoor.jpg" width="64" height="64"/><a href="http://web.mit.edu/torralba/www/indoor.html"> 
              Indoor Scene Recognition Database</a> (2009). The database contains 67 Indoor categories, and a total of 15620 images.</p>
                 
               <p><img src="assets/images/tinyimagesthumb.jpg" width="64" height="64"/><a href="http://people.csail.mit.edu/torralba/tinyimages/"> 80 Million tiny images: explore a dense 
              sampling of the visual world</a> (2008). The web page shows a visual index of all the noums in WordNet. A portion of this dataset was manualy curated and used to create the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a> datasets. The resulting CIFAR dataset was used to develop some of the early neural nets around 2010. Although the images are too small to train working systems (images only have 32x32 pixels), the dataset is important for fundamental research.</p>
-->
           <p><img src="./Antonio Torralba_files/labelMeiPhoneIcon.png" width="64" height="64"><a href="https://github.com/CSAILVision/LabelMeAnnotationTool">LabelMe</a> (2005). The goal of LabelMe is to provide an online annotation tool to build image databases for computer vision research. LabelMe started so long ago ... it is hard to believe it is still up an running.  <!--The code is avalable here: <a href="https://github.com/CSAILVision/LabelMeAnnotationTool">github</a>. -->

           </p><p><img src="./Antonio Torralba_files/MixtureRealSketch.jpg" width="64" height="64"><a href="http://people.csail.mit.edu/torralba/code/spatialenvelope/">8 scene categories database</a> (2001). This dataset contains 8 outdoor scene categories: coast, mountain, forest, open country, street, inside city, tall buildings and highways. There are 2600 color images, 256x256 pixels. 

          <br>
        </p></div>       
        <br>

 <!----------------------------------PUBLICATIONS ------------------------------------- -->
        <div id="publications">
          <h2>Publications</h2>
            <h3>2021</h3>

            <ul>
                <li><a href="https://mbaradad.github.io/learning_with_noise/">Learning to See by Looking at Noise.</a>
                    <span class="authors">Manel Baradad*, Jonas Wulff*, Tongzhou Wang, Phillip Isola, Antonio Torralba.</span>
                    <span class="journal">NeurIPS 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://phystouch.csail.mit.edu/">Dynamic Modeling of Hand-Object Interactions via Tactile Sensing.</a>
                    <span class="authors">Qiang Zhang*, Yunzhu Li*, Yiyue Luo, Wan Shou, Michael Foshey, Junchi Yan, Joshua B. Tenenbaum, Wojciech Matusik, and Antonio Torralba.</span>
                    <span class="journal">IROS 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="hhttps://openaccess.thecvf.com/content/ICCV2021/papers/Lin_BARF_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2021_paper.pdf">BARF: Bundle-Adjusting Neural Radiance Fields.</a>
                    <span class="authors">Chen-Hsuan Lin, Wei-Chiu Ma, Antonio Torralba, Simon Lucey.</span>
                    <span class="journal">ICCV 2021.</span>
                </li>
            </ul>

           <ul>
                <li><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Papadopoulos_Scaling_Up_Instance_Annotation_via_Label_Propagation_ICCV_2021_paper.pdf">Scaling Up Instance Annotation via Label Propagation.</a>
                    <span class="authors">Dim P. Papadopoulos, Ethan Weber, Antonio Torralba.</span>
                    <span class="journal">ICCV 2021.</span>
                </li>
            </ul>

           <ul>
                <li><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Papadopoulos_Scaling_Up_Instance_Annotation_via_Label_Propagation_ICCV_2021_paper.pdf">Toward a Visual Concept Vocabulary for GAN Latent Space.</a>
                    <span class="authors">Sarah Schwettmann, Evan Hernandez, David Bau, Samuel Klein, Jacob Andreas, Antonio Torralba.</span>
                    <span class="journal">ICCV 2021.</span>
                </li>
            </ul>

           <ul>
                <li><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Sharma_What_You_Can_Learn_by_Staring_at_a_Blank_Wall_ICCV_2021_paper.pdf">What You Can Learn by Staring at a Blank Wall.</a>
                    <span class="authors">Prafull Sharma, Miika Aittala, Yoav Y. Schechner, Antonio Torralba, Gregory W. Wornell, William T. Freeman, Fredo Durand.</span>
                    <span class="journal">ICCV 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Sharma_What_You_Can_Learn_by_Staring_at_a_Blank_Wall_ICCV_2021_paper.pdf">Weakly Supervised Human-Object Interaction Detection in Video via Contrastive Spatiotemporal Regions.</a>
                    <span class="authors">Shuang Li, Yilun Du, Antonio Torralba, Josef Sivic, Bryan Russell.</span>
                    <span class="journal">ICCV 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://3d-representation-learning.github.io/nerf-dy/">3D Neural Scene Representations for Visuomotor Control.</a>
                    <span class="authors">Yunzhu Li*, Shuang Li*, Vincent Sitzmann, Pulkit Agrawal, and Antonio Torralba.</span>
                    <span class="journal">CoRL 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://nv-tlabs.github.io/datasetGAN/">DatasetGAN: Efficient Labeled Data Factory with Minimal Human Effort.</a>
                    <span class="authors">Yuxuan Zhang, Huan Ling, Jun Gao, Kangxue Yin, Jean-Francois Lafleche, Adela Barriuso, Antonio Torralba, Sanja Fidler.</span>
                    <span class="journal">CVPR 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://nv-tlabs.github.io/semanticGAN/">Semantic Segmentation with Generative Models: Semi-Supervised Learning and Strong Out-of-Domain Generalization.</a>
                    <span class="authors">Daiqing Li, Junlin Yang, Karsten Kreis, Antonio Torralba, Sanja Fidler.</span>
                    <span class="journal">CVPR 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://nv-tlabs.github.io/DriveGAN/">DriveGAN: Towards a Controllable High-Quality Neural Simulation.</a>
                    <span class="authors">Seung Wook Kim, Jonah Philion, Antonio Torralba, Sanja Fidler.</span>
                    <span class="journal">CVPR 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://groups.csail.mit.edu/vision/torralbalab/">IntelligentCarpet: Inferring 3D Human Pose from Tactile Signals.</a>
                    <span class="authors">Y.Luo, Y.Li, M. Foshey, W. Shou, P. Sharma, T. Palacios, A. Torralba, W. Matusik.</span>
                    <span class="journal">CVPR 2021.</span>
                </li>
            </ul>


            <ul>
                <li><a href="http://virtual-home.org/watch_and_help/">Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration.</a>
                    <span class="authors">X Puig, T Shu, S Li, Z Wang, JB Tenenbaum, S Fidler, A Torralba.</span>
                    <span class="journal">International Conference on Learning Representations (ICLR), 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/abs/2010.09125">Image GANs meet differentiable rendering for inverse graphics and interpretable 3d neural rendering.</a>
                    <span class="authors">Y Zhang, W Chen, H Ling, J Gao, Y Zhang, A Torralba, S Fidler.</span>
                    <span class="journal">International Conference on Learning Representations (ICLR), 2021.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://senstextile.csail.mit.edu//">Learning Human-environment Interactions using Conformal Tactile Textiles.</a>
                    <span class="authors">Y.Luo, Y.Li, P. Sharma, W. Shou, K. Wu, M. Foshey, B. Li, T. Palacios, A. Torralba, W. Matusik.</span>
                    <span class="journal">Nature Electronics, 4, 193–201, 2021.</span>
                </li>
            </ul>

            <h3>2020</h3>

            <ul>
                <li><a href="https://dissect.csail.mit.edu/">Understanding the role of individual units in a deep neural network.</a>
                    <span class="authors">D Bau, JY Zhu, H Strobelt, A Lapedriza, B Zhou, A Torralba.</span>
                    <span class="journal">Proceedings of the National Academy of Sciences. Sept 2020.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://www.wpeebles.com/hessian-penalty.html">The hessian penalty: A weak prior for unsupervised disentanglement.</a>
                    <span class="authors">W Peebles, J Peebles, JY Zhu, A Efros, A Torralba.</span>
                    <span class="journal">European Conference on Computer Vision. ECCV 2020.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://rewriting.csail.mit.edu/">Rewriting a Deep Generative Model.</a>
                    <span class="authors">D Bau, S Liu, T Wang, JY Zhu, A Torralba.</span>
                    <span class="journal">European Conference on Computer Vision, 351-369. ECCV 2020.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://people.csail.mit.edu/weichium/papers/eccv20-deep-optimizer/">Deep feedback inverse problem solver.</a>
                    <span class="authors">WC Ma, S Wang, J Gu, S Manivasagam, A Torralba, R Urtasun.</span>
                    <span class="journal">European Conference on Computer Vision, 229-246. ECCV 2020.</span>
                </li>
            </ul>


            <ul>
                <li><a href="http://foley-music.csail.mit.edu/">Foley Music: Learning to Generate Music from Videos.</a>
                    <span class="authors">Chuang Gan, Deng Huang, Peihao Chen, Joshua B. Tenenbaum, Antonio Torralba.</span>
                    <span class="journal">European Conference on Computer Vision, ECCV 2020.</span>
                </li>
            </ul>


            <ul>
                <li><a href="http://incidentsdataset.csail.mit.edu/">Detecting natural disasters, damage, and incidents in the wild.</a>
                    <span class="authors">E Weber, N Marzo, DP Papadopoulos, A Biswas, A Lapedriza, F Ofli, M Imran, A Torralba.</span>
                    <span class="journal">European Conference on Computer Vision, ECCV 2020.</span>
                </li>
            </ul>


            <ul>
                <li><a href="https://github.com/chingyaoc/DCL">Debiased contrastive learning.</a>
                    <span class="authors">CY Chuang, J Robinson, YC Lin, A Torralba, S Jegelka.</span>
                    <span class="journal">Advances in Neural Information Processing Systems 33. NeurIPS 2020.</span>
                </li>
            </ul>


            <ul>
                <li><a href="https://yunzhuli.github.io/V-CDN/">Causal discovery in physical systems from videos.</a>
                    <span class="authors">Y Li, A Torralba, A Anandkumar, D Fox, A Garg.</span>
                    <span class="journal">Advances in Neural Information Processing Systems 33. NeurIPS 2020.</span>
                </li>
            </ul>


            <ul>
                <li><a href="https://arxiv.org/abs/2007.03511">Estimating Generalization under Distribution Shifts via Domain-Invariant Representations.</a>
                    <span class="authors">Ching-Yao Chuang, Antonio Torralba, and Stefanie Jegelka</span>
                    <span class="journal">ICML 2020.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://clevrer.csail.mit.edu/">CLEVRER: CoLlision Events for Video REpresentation and Reasoning.</a>
                    <span class="authors">Kexin Yi*, Chuang Gan*, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, Joshua B. Tenenbaum.</span>
                    <span class="journal">ICLR 2020.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://dap.csail.mit.edu/">Deep Audio Priors Emerge From Harmonic Convolutional Networks.</a>
                    <span class="authors">Zhoutong Zhang, Yunyun Wang, Chuang Gan, Jiajun Wu, Joshua B. Tenenbaum, Antonio Torralba, William T. Freeman.</span>
                    <span class="journal">ICLR 2020.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://koopman.csail.mit.edu/">Learning Compositional Koopman Operators for Model-Based Control.</a>
                    <span class="authors">Yunzhu Li*, Hao He*, Jiajun Wu, Dina Katabi, and Antonio Torralba.</span>
                    <span class="journal">ICLR 2020.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://music-gesture.csail.mit.edu/">Music Gesture for Visual Sound Separation.</a>
                    <span class="authors">Chuang Gan, Deng Huang, Hang Zhao, Joshua B. Tenenbaum, Antonio Torralba.</span>
                    <span class="journal">CVPR 2020.</span>
                </li>
            </ul>


            <ul>
                <li><a href="https://github.com/mbaradad/im2pcl">Height and Uprightness Invariance for 3D Prediction from a Single View.</a>
                    <span class="authors">Manel Baradad and Antonio Torralba.</span>
                    <span class="journal">CVPR 2020.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://selfcondgan.csail.mit.edu/">Diverse Image Generation via Self-Conditioned GANs.</a>
                    <span class="authors">Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, Antonio Torralba.</span>
                    <span class="journal">CVPR 2020.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://nv-tlabs.github.io/gameGAN/">Learning to Simulate Dynamic Environments with GameGAN.</a>
                    <span class="authors">Seung Wook Kim, Yuhao Zhou, Jonah Philion, Antonio Torralba, Sanja Fidler.</span>
                    <span class="journal">CVPR 2020.</span>
                </li>
            </ul>

            <h3>2019</h3>

            <ul>
                <li><a href="https://link.springer.com/epdf/10.1007/s11263-019-01205-0?author_access_token=fpRjlRrXAdFcqHloJKbBw_e4RwlQNchNByi7wbcMAY6Lgrm32m2EUaKC16hIg22R0JMq3deQiMohKPqc8CBJLtGu9ys6QZR7mhluO5HUZnAgBmGB47fMcWjI5rYrxemiodIZFNmYVS1HscU7_YhGXg%3D%3D">Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input.</a>
                    <span class="authors">David Harwath, Adria Recasens, Dıdac Surıs, Galen Chuang, Antonio Torralba, and James Glass.</span>
                    <span class="journal">IJCV 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://gandissect.csail.mit.edu/papers/Seeing_What_a_GAN_Cannot_Generate.pdf/">Seeing What a GAN Cannot Generate.</a>
                    <span class="authors">D Bau, JY Zhu, J Wulff, W Peebles, H Strobelt, B Zhou, A Torralba.</span>
                    <span class="journal">ICCV 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://gaze360.csail.mit.edu/">Gaze360: Physically Unconstrained Gaze Estimation in the Wild.</a>
                    <span class="authors">P. Kellnhofer*, A. Recasens*, S. Stent, W. Matusik and A. Torralba.</span>
                    <span class="journal">ICCV 2019.</span>
                </li>
            </ul>

             <ul>
                <li><a href="http://openaccess.thecvf.com/content_ICCV_2019/html/Gan_Self-Supervised_Moving_Vehicle_Tracking_With_Stereo_Sound_ICCV_2019_paper.html">Self-supervised Moving Vehicle Tracking with Stereo Sound.</a>
                    <span class="authors">Chuang Gan, Hang Zhao, Peihao Chen, David Cox, Antonio Torralba.</span>
                    <span class="journal">ICCV 2019.</span>
                </li>
            </ul>

             <ul>
                <li><a href="http://openaccess.thecvf.com/content_ICCV_2019/html/Zhao_Through-Wall_Human_Mesh_Recovery_Using_Radio_Signals_ICCV_2019_paper.html">Through-Wall Human Mesh Recovery Using Radio Signals.</a>
                    <span class="authors">Mingmin Zhao, Yingcheng Liu, Aniruddh Raghu, Hang Zhao, Tianhong Li, Antonio Torralba, Dina Katabi.</span>
                    <span class="journal">ICCV 2019.</span>
                </li>
            </ul>

             <ul>
                <li><a href="https://arxiv.org/pdf/1904.05979.pdf">The Sound of Motions.</a>
                    <span class="authors">Hang Zhao, Chuang Gan, Wei-Chiu Ma, Antonio Torralba.</span>
                    <span class="journal">ICCV 2019.</span>
                </li>
            </ul>

             <ul>
                <li><a href="http://hacs.csail.mit.edu/">HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization.</a>
                    <span class="authors">Hang Zhao, Zhicheng Yan, Lorenzo Torresani, Antonio Torralba.</span>
                    <span class="journal">ICCV 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://nv-tlabs.github.io/meta-sim/">Meta Sim: Learning to Generate Synthetic Datasets.</a>
                    <span class="authors">Amlan Kar, Aayush Prakash, Ming-Yu Liu, Eric Cameracci, Justin Yuan, Matt Rusiniak, David Acuna, Antonio Torralba, Sanja Fidler.</span>
                    <span class="journal">ICCV 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://openaccess.thecvf.com/content_ICCV_2019/html/Chu_Neural_Turtle_Graphics_for_Modeling_City_Road_Layouts_ICCV_2019_paper.html">Neural Turtle Graphics for Modeling City Road Layouts.</a>
                    <span class="authors">Hang Chu, Daiqing Li, David Acuna, Amlan Kar, Maria Shugrina, Xinkai Wei, Ming-Yu Liu, Antonio Torralba , Sanja Fidler.</span>
                    <span class="journal">ICCV 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://ganpaint.io/">Semantic Photo Manipulation with a Generative Image Prior.</a>
                    <span class="authors">David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou, Jun-Yan Zhu, Antonio Torralba.</span>
                    <span class="journal">SIGGRAPH 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://stag.csail.mit.edu/">Learning the Signatures of the Human Grasp Using a Scalable Tactile Glove.</a>
                    <span class="authors">Subramanian Sundaram, Petr Kellnhofer, Yunzhu Li, Jun-Yan Zhu, Antonio Torralba, and Wojciech Matusik.</span>
                    <span class="journal">Nature, 569 (7758), 2019.</span>
                    <a class="resource" href="http://stag.csail.mit.edu/">Project page.</a>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/pdf/1810.06553.pdf/">Recipe1M+: A Dataset for Learning Cross-Modal Embeddings for Cooking Recipes and Food Images.</a>
                    <span class="authors">Javier Marin, Aritro Biswas, Ferda Ofli, Nicholas Hynes, Amaia Salvador, Yusuf Aytar, Ingmar Weber, and Antonio Torralba.</span>
                    <span class="journal">IEEE transactions on pattern analysis and machine intelligence.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/pdf/1806.07011.pdf">Synthesizing Environment-Aware Activities via Activity Sketches.</a>
                    <span class="authors">A. Liao*, X. Puig*, M. Boben, A. Torralba, S.Fidler.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR), 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Connecting_Touch_and_Vision_via_Cross-Modal_Prediction_CVPR_2019_paper.pdf">Connecting Touch and Vision via Cross-Modal Prediction.</a>
                    <span class="authors">Yunzhu Li, Jun-Yan Zhu, Russ Tedrake, Antonio Torralba.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR), 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://pizzagan.csail.mit.edu/">How to Make a Pizza: Learning a Compositional Layer-Based GAN Model.</a>
                    <span class="authors">DP Papadopoulos, Y Tamaazousti, F Ofli, I Weber, A Torralba.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR), 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://groups.csail.mit.edu/vision/torralbalab/papers/suris_cvpr_2019.pdf">Learning Words by Drawing Images.</a>
                    <span class="authors">Dídac Surís*, Adrià Recasens*, David Bau, David Harwath, James Glass and Antonio Torralba.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR), 2019.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/pdf/1608.05442.pdf">Semantic Understanding of Scenes through ADE20K Dataset.</a>
                    <span class="authors">Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso and Antonio Torralba.</span>
                    <span class="journal">International Journal of Computer Vision. March 2019, Volume 127, Issue 3, pp 302–321.</span>
                    <a class="resource" href="http://groups.csail.mit.edu/vision/datasets/ADE20K/">ADE20K Dataset</a> |
                    <a class="resource" href="http://sceneparsing.csail.mit.edu/" target="_blank">Challenge Page</a> |
                    <a class="resource" href="https://github.com/CSAILVision/sceneparsing" target="_blank">Toolkit+Code</a> |
                    <a class="resource" href="http://scenesegmentation.csail.mit.edu/" target="_blank">Demo</a>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/pdf/1904.09013.pdf">Self-supervised Audio-visual Co-segmentation.</a>
                    <span class="authors">Andrew Rouditchenko, Hang Zhao, Chuang Gan, Josh McDermott, Antonio Torralba</span>
                    <span class="journal">ICASSP 2019</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/pdf/1811.10597.pdf">GAN Dissection: Visualizing and Understanding Generative Adversarial Networks.</a>
                    <span class="authors">David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B. Tenenbaum, William T. Freeman, Antonio Torralba.</span>
                    <span class="journal">ICLR 2019</span>
                    <a class="resource" href="http://gandissect.csail.mit.edu/">Project page</a> 
                </li>
            </ul>

             <ul>
                <li><a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Angie_W_Boggust_Grounding_Spoken_Words_in_Unlabeled_Video_CVPRW_2019_paper.pdf">Grounding Spoken Words in Unlabeled Video.</a>
                    <span class="authors">Angie Boggust, Kartik Audhkhasi, Dhiraj Joshi, David Harwath, Samuel Thomas, Rogerio Feris, Danny Gutfreund, Yang Zhang, Antonio Torralba, Michael Picheny, James Glass.</span>
                    <span class="journal">Sight and Sounds CVPR Workshop</span>
                </li>
            </ul>

           <ul>
                <li><a href="http://people.csail.mit.edu/liyunzhu/projects/dpi/dpi-paper.pdf">Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable Objects, and Fluids.</a>
                    <span class="authors">Yunzhu Li, Jiajun Wu, Russ Tedrake, Joshua B. Tenenbaum, and Antonio Torralba.</span>
                    <span class="journal">ICLR 2019</span>
                    <a class="resource" href="http://dpi.csail.mit.edu/">Project page</a> | <a class="resource" href="https://www.youtube.com/watch?v=nQipmVDuytQ">Video</a>
                </li>
            </ul>

            <ul>
                <li><a href="http://people.csail.mit.edu/liyunzhu/projects/propnet/propnet-paper.pdf">Propagation Networks for Model-Based Control Under Partial Observation.</a>
                    <span class="authors">Yunzhu Li, Jiajun Wu, Jun-Yan Zhu, Joshua B. Tenenbaum, Antonio Torralba, and Russ Tedrake.</span>
                    <span class="journal">ICRA 2019</span>
                    <a class="resource" href="http://propnet.csail.mit.edu/">Project page</a> | <a class="resource" href="https://www.youtube.com/watch?v=vB8fg-yQs-I">Video</a>
                </li>
            </ul>


            <h3>2018</h3>

            <ul>
                <li><a href="https://arxiv.org/abs/1811.10959">Dataset Distillation.</a>
                    <span class="authors">Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, Alexei A. Efros.</span>
                    <span class="journal">arXiv 2018</span>
                    <a class="resource" href="https://ssnl.github.io/dataset_distillation/">Project page</a>
                </li>
            </ul>


            <ul>
                <li><a href="http://papers.nips.cc/paper/7381-neural-symbolic-vqa-disentangling-reasoning-from-vision-and-language-understanding.pdf">Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding.</a>
                    <span class="authors">Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli, and Josh Tenenbaum.</span>
                    <span class="journal">NeurIPS 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://papers.nips.cc/paper/7459-3d-aware-scene-manipulation-via-inverse-graphics.pdf">3D-Aware Scene Manipulation via Inverse Graphics.</a>
                    <span class="authors">Shunyu Yao, Tzu Ming Hsu, Jun-Yan Zhu, Jiajun Wu, Antonio Torralba, Bill Freeman, and Josh Tenenbaum.</span>
                    <span class="journal">NeurIPS 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://papers.nips.cc/paper/7297-visual-object-networks-image-generation-with-disentangled-3d-representations.pdf">Visual Object Networks: Image Generation with Disentangled 3D Representations.</a>
                    <span class="authors">Jun-Yan Zhu, Zhoutong Zhang, Chengkai Zhang, Jiajun Wu, Antonio Torralba, Josh Tenenbaum, and Bill Freeman.</span>
                    <span class="journal">NeurIPS 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/pdf/1804.01452.pdf">Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input.</a>
                    <span class="authors">David Harwath, Adria Recasens, Dıdac Surıs, Galen Chuang, Antonio Torralba, and James Glass.</span>
                    <span class="journal">European Conference on Computer Vision (ECCV) 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://relation.csail.mit.edu/">Temporal Relational Reasoning in Videos.</a>
                    <span class="authors">Bolei Zhou, Alex Andonian, Aude Oliva, and Antonio Torralba.</span>
                    <span class="journal">European Conference on Computer Vision (ECCV) 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://groups.csail.mit.edu/vision/torralbalab/">Single Image Intrinsic Decomposition Without a Single Intrinsic Image.</a>
                    <span class="authors">Wei-Chiu Ma, Hang Chu, Bolei Zhou, Raquel Urtasun, Antonio Torralba.</span>
                    <span class="journal">European Conference on Computer Vision (ECCV) 2018</span>
                </li>
            </ul>

           <ul>
                <li><a href="https://arxiv.org/pdf/1809.03355.pdf">Learning to Zoom: a Saliency-Based Sampling Layer for Neural Networks.</a>
                    <span class="authors">A. Recasens*, P. Kellnhofer*, S. Stent, W. Matusik and A. Torralba</span>
                    <span class="journal">European Conference on Computer Vision (ECCV) 2018</span>
                    <a class="resource" href="https://github.com/recasens/Saliency-Sampler/">Project page</a> 
                </li>
            </ul>

            <ul>
                <li><a href="http://sound-of-pixels.csail.mit.edu/">The Sound of Pixels.</a>
                    <span class="authors">H Zhao, C Gan, A Rouditchenko, C Vondrick, J McDermott, A Torralba.</span>
                    <span class="journal">European Conference on Computer Vision (ECCV) 2018</span>
                </li>
            </ul>

           <ul>
                <li><a href="https://groups.csail.mit.edu/vision/torralbalab/">Interpretable Basis Decomposition for Visual Explanation.</a>
                    <span class="authors">Bolei Zhou, Yiyou Sun, David Bau, Antonio Torralba.</span>
                    <span class="journal">European Conference on Computer Vision (ECCV) 2018</span>
                </li>
            </ul>

           <ul>
                <li><a href="http://people.csail.mit.edu/mingmin/papers/rfpose3d-sigcomm-zhao.pdf">RF-based 3D Skeletons.</a>
                    <span class="authors">Mingmin Zhao, Yonglong Tian, Hang Zhao, Mohammad Abu Alsheikh, Tianhong Li, Rumen Hristov, Zachary Kabelac, Dina Katabi, Antonio Torralba.</span>
                    <span class="journal">Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://openaccess.thecvf.com/content_cvpr_2018/html/2406.html">Through-wall human pose estimation using radio signals.</a>
                    <span class="authors">M Zhao, T Li, M Abu Alsheikh, Y Tian, H Zhao, A Torralba, D Katabi.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR) 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://virtual-home.org/">VirtualHome: Simulating Household Activities via Programs.</a>
                    <span class="authors">Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, Antonio Torralba.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR) 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Baradad_Inferring_Light_Fields_CVPR_2018_paper.pdf">Inferring Light Fields From Shadows.</a>
                    <span class="authors">Manel Baradad, Vickie Ye, Adam B Yedidia, Frédo Durand, William T Freeman, Gregory W Wornell, Antonio Torralba.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR) 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://www.cs.utoronto.ca/~cychuang/learning2act/">Learning to Act Properly: Predicting and Explaining Affordances from Images.</a>
                    <span class="authors">CY Chuang, J Li, A Torralba, S Fidler.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR) 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://groups.csail.mit.edu/vision/torralbalab/">Real-Time Object Pose Estimation with Pose Interpreter Networks.</a>
                    <span class="authors">Jimmy Wu, Bolei Zhou, Rebecca Russell, Vincent Kee, Syler Wagner, Mitchell Hebert, Antonio Torralba, and David M.S. Johnson.</span>
                    <span class="journal">International Conference on Intelligent Robots (IROS), 2018</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://ieeexplore.ieee.org/abstract/document/8345763/">Exploiting occlusion in non-line-of-sight active imaging.</a>
                    <span class="authors">Christos Thrampoulidis, Gal Shulkind, Feihu Xu, William T Freeman, Jeffrey Shapiro, Antonio Torralba, Franco Wong, Gregory Wornell.</span>
                    <span class="journal">IEEE Transactions on Computational Imaging.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/pdf/1806.02891.pdf">Revisiting the Importance of Individual Units in CNNs via Ablation.</a>
                    <span class="authors">B Zhou, Y Sun, D Bau, A Torralba.</span>
                    <span class="journal">arXiv preprint arXiv:1806.02891</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://www.osapublishing.org/oe/abstract.cfm?uri=oe-26-8-9945">Revealing hidden scenes by photon-efficient occlusion-based opportunistic active imaging.</a>
                    <span class="authors">Feihu Xu, Gal Shulkind, Christos Thrampoulidis, Jeffrey H Shapiro, Antonio Torralba, Franco NC Wong, Gregory W Wornell.</span>
                    <span class="journal">Optical Society of America.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/abs/1804.01452">Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input.</a>
                    <span class="authors">D Harwath, A Recasens, D Surís, G Chuang, A Torralba, J Glass.</span>
                    <span class="journal">arXiv preprint arXiv:1804.01452</span>
                </li>
            </ul>
            
            <ul>
                <li><a href="https://arxiv.org/pdf/1804.00782.pdf">3D Interpreter Networks for Viewer-Centered Wireframe Modeling.</a>
                    <span class="authors">J Wu, T Xue, JJ Lim, Y Tian, JB Tenenbaum, A Torralba, WT Freeman.</span>
                    <span class="journal">International Journal of Computer Vision, 1-18</span>
                </li>
            </ul>

            <h3>2017</h3>
            <ul>
                <li><a href="https://arxiv.org/pdf/1712.07271.pdf">Learning Sight from Sound: Ambient Sound Provides Supervision for Visual Learning.</a>
                    <span class="authors">A Owens, J Wu, JH McDermott, WT Freeman, A Torralba.</span>
                    <span class="journal">International Journal of Computer Vision, vol 126, 2018.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/abs/1711.06297">Exploiting Occlusion in Non-Line-of-Sight Active Imaging.</a>
                    <span class="authors">Christos Thrampoulidis, Gal Shulkind, Feihu Xu, William T Freeman, Jeffrey H Shapiro, Antonio Torralba, Franco NC Wong, Gregory W Wornell.</span>
                    <span class="journal">arXiv preprint arXiv:1711.06297</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/abs/1711.05611">Interpreting Deep Visual Representations via Network Dissection.</a>
                    <span class="authors">Bolei Zhou, David Bau, Aude Oliva, Antonio Torralba.</span>
                    <span class="journal">arXiv preprint arXiv:1711.05611</span>
                </li>
            </ul>

           <ul>
                <li><a href="http://people.csail.mit.edu/recasens/docs/videogazefollow.pdf">Following gaze in video.</a>
                    <span class="authors">Adrià Recasens, Carl Vondrick, Aditya Khosla and Antonio Torralba.</span>
                    <span class="journal">International Conference in Computer Vision (ICCV), 2017.</span>
                </li>
            </ul>
            
            <ul>
                <li><a href="http://people.csail.mit.edu/recasens/docs/videogazefollow.pdf">Turning Corners into Cameras: Principles and Methods.</a>
                    <span class="authors">K.L. Bouman, V. Ye, A.B. Yedidia, F. Durand, G.W. Wornell, A. Torralba, W.T. Freeman.</span>
                    <span class="journal">International Conference in Computer Vision (ICCV), 2017.</span>
                </li>
            </ul>
            
            <ul>
                <li><a href="http://arxiv.org/abs/1703.08769">Open vocabulary scene parsing.</a>
                    <span class="authors">Hang Zhao, Xavier Puig, Bolei Zhou, Sanja Fidler, Antonio Torralba.</span>
                    <span class="journal">International Conference in Computer Vision (ICCV), 2017.</span>
                </li>
            </ul>
            
            <ul>
                <li><a href="http://carlvondrick.com/cmplaces_pami.pdf">Cross-Modal Scene Networks.</a>
                    <span class="authors">Yusuf Aytar*, Lluis Castrejon*, Carl Vondrick, Hamed Pirsiavash, Antonio Torralba.</span>
                    <span class="journal">IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017.</span>
                    <a class="resource" href="http://projects.csail.mit.edu/cmplaces/">Project page</a> 
                </li>
            </ul>
            
            <ul>
                <li><a href="http://people.csail.mit.edu/yusuf/see-hear-read/paper.pdf">See, Hear, and Read: Deep Aligned Representations.</a>
                    <span class="authors">Yusuf Aytar, Carl Vondrick, Antonio Torralba.</span>
                    <span class="journal">arXiv.</span>
                    <a class="resource" href="http://people.csail.mit.edu/yusuf/see-hear-read/">Project page</a> 
                </li>
            </ul>
            
            <ul>
                <li><a href="http://carlvondrick.com/mistaken.pdf">Who is Mistaken?</a>
                    <span class="authors">Benjamin Eysenbach, Carl Vondrick, Antonio Torralba.</span>
                    <span class="journal">arXiv.</span>
                    <a class="resource" href="http://people.csail.mit.edu/bce/mistaken/">Project page</a> 
                </li>
            </ul>
            
            <ul>
                <li><a href="http://netdissect.csail.mit.edu/final-network-dissection.pdf">Network Dissection: Quantifying Interpretability of Deep Visual Representations.</a>
                    <span class="authors">David Bau*, Bolei Zhou*, Aditya Khosla, Aude Oliva, and Antonio Torralba.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR), 2017.</span>
                    <a class="resource" href="http://netdissect.csail.mit.edu/">Project page</a> | <a class="resource" href="https://github.com/CSAILVision/NetDissect">Code release</a>
                </li>
            </ul>
            
            <ul>
                <li><a href="http://web.mit.edu/vondrick/transformer.pdf">Generating the Future with Adversarial Transformers.</a>
                    <span class="authors">Carl Vondrick, Antonio Torralba.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR), 2017.</span>
                </li>
            </ul>
            
            
            <ul>
                <li><a href="https://arxiv.org/pdf/1608.05442.pdf">Scene Parsing through ADE20K Dataset.</a>
                    <span class="authors">B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso and A. Torralba.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR), 2017.</span>
                    <a class="resource" href="http://groups.csail.mit.edu/vision/datasets/ADE20K/">ADE20K Dataset</a> |
                    <a class="resource" href="http://sceneparsing.csail.mit.edu/" target="_blank">Challenge Page</a> |
                    <a class="resource" href="https://github.com/CSAILVision/sceneparsing" target="_blank">Toolkit+Code</a> |
                    <a class="resource" href="http://scenesegmentation.csail.mit.edu/" target="_blank">Demo</a>
                </li>
            </ul>
            
            <ul>
                <li><a href="http://im2recipe.csail.mit.edu/">Learning Cross-modal Embeddings for Cooking Recipes and Food Images.</a>
                    <span class="authors">A. Salvador*, N. Hynes*, Y. Aytar, J. Marin, F. Ofli, I. Weber, A. Torralba.</span>
                    <span class="journal">Computer Vision and Pattern Recognition (CVPR), 2017.</span>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/abs/1612.00341">A Compositional Object-Based Approach to Learning Physical Dynamics.</a>
                    <span class="authors">Michael B. Chang, Tomer Ullman, Antonio Torralba, Joshua B. Tenenbaum.</span>
                    <span class="journal">ICLR 2017.</span>
                </li>
            </ul>


            <h3>2016</h3>

            <ul>
                <li><a href="https://arxiv.org/pdf/1608.05442.pdf">Semantic Understanding of Scenes through ADE20K Dataset.</a>
                    <span class="authors">B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso and A. Torralba.</span>
                    <span class="journal">International Journal of Computer Vision.</span>
                    <a class="resource" href="http://groups.csail.mit.edu/vision/datasets/ADE20K/">ADE20K Dataset</a> |
                    <a class="resource" href="http://sceneparsing.csail.mit.edu/" target="_blank">Challenge Page</a> |
                    <a class="resource" href="https://github.com/CSAILVision/sceneparsing" target="_blank">Toolkit+Code</a> |
                    <a class="resource" href="http://scenesegmentation.csail.mit.edu/" target="_blank">Demo</a>
                </li>
            </ul>

            <ul>
                <li><a href="https://arxiv.org/pdf/1610.09001.pdf">SoundNet: Learning Sound Representations from Unlabeled Video.</a>
                    <span class="authors">Yusuf Aytar, Carl Vondrick, Antonio Torralba.</span>
                    <span class="journal">Advances in Neural Information Processing Systems (NIPS),  2016.</span>
                    <a class="resource" href="http://projects.csail.mit.edu/soundnet/">Project page</a> 
                </li>
            </ul>

            <ul>
                <li><a href="http://web.mit.edu/vondrick/tinyvideo/paper.pdf">Generating Videos with Scene Dynamics.</a>
                    <span class="authors">Carl Vondrick, Hamed Pirsiavash, Antonio Torralba.</span>
                    <span class="journal">Advances in Neural Information Processing Systems (NIPS),  2016.</span>
                    <a class="resource" href="http://web.mit.edu/vondrick/tinyvideo/">Project page</a> 
               </li>
            </ul>

            <ul>
                <li><a href="http://papers.nips.cc/paper/6186-unsupervised-learning-of-spoken-language-with-visual-context.pdf">Unsupervised Learning of Spoken Language with Visual Context.</a>
                    <span class="authors">David Harwath, Antonio Torralba, James Glass.</span>
                    <span class="journal">Advances in Neural Information Processing Systems (NIPS),  2016.</span>
                </li>
            </ul>


            <ul>
                <li><a href="https://arxiv.org/pdf/1608.07017.pdf">Ambient Sound Provides Supervision for Visual Learning.</a>
                    <span class="authors">Andrew Owens, Jiajun Wu, Josh H. McDermott, William T. Freeman, and Antonio Torralba.</span>
                    <span class="journal">European Conference in Computer Vision (ECCV),  2016.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://people.csail.mit.edu/recasens/docs/bylinskii_eccv2016.pdf">Where should saliency models look next?</a>
                    <span class="authors">Zoya Bylinskii, Adrià Recasens, Ali Borji, Aude Oliva, Fredo Durand and Antonio Torralba.</span>
                    <span class="journal">European Conference in Computer Vision (ECCV),  2016.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://people.csail.mit.edu/tfxue/papers/eccv2016_3DINN.pdf">Single Image 3D Interpreter Network.</a>
                    <span class="authors">Jiajun Wu, Tianfan Xue, Joseph J. Lim, Yuandong Tian, Joshua B. Tenenbaum, Antonio Torralba, and William T. Freeman.</span>
                    <span class="journal">European Conference in Computer Vision (ECCV),  2016.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://arxiv.org/abs/1512.04150">Learning Deep Features for Discriminative Localization.</a>
                    <span class="authors">Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba.</span>
                    <span class="journal">Conference on Computer Vision and Pattern Recognition (CVPR),  2016.</span>
                    <a class="resource" href="http://cnnlocalization.csail.mit.edu/">Project page</a> 
                </li>
            </ul>

            <ul>
                <li><a href="http://arxiv.org/abs/1512.02902">MovieQA: Understanding Stories in Movies through Question-Answering.</a>
                    <span class="authors">Makarand Tapaswi, Yukun Zhu, Reiner Stiefelhagen, Antonio Torralba, Raquel Urtasun, Sanja Fidler.</span>
                    <span class="journal">Conference on Computer Vision and Pattern Recognition (CVPR),  2016.</span>
                    <a class="resource" href="http://movieqa.cs.toronto.edu/home/">Project page</a>
                </li>
            </ul>

            <ul>
                <li><a href="http://web.mit.edu/vondrick/adaptation.pdf">Learning Aligned Cross-Modal Representations from Weakly Aligned Data.</a>
                    <span class="authors">Lluis Castrejon*, Yusuf Aytar*, Carl Vondrick, Hamed Pirsiavash, Antonio Torralba.</span>
                    <span class="journal">Conference on Computer Vision and Pattern Recognition (CVPR),  2016.</span>
                    <a class="resource" href="http://projects.csail.mit.edu/cmplaces/">Project page</a>
                </li>
            </ul>

            <ul>
                <li><a href="http://web.mit.edu/vondrick/intention.pdf">Predicting Motivations of Actions by Leveraging Text.</a>
                    <span class="authors"> Carl Vondrick, Deniz Oktay, Hamed Pirsiavash, Antonio Torralba.</span>
                    <span class="journal">Conference on Computer Vision and Pattern Recognition (CVPR),  2016.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://web.mit.edu/vondrick/prediction.pdf">Anticipating Visual Representations from Unlabeled Video.</a>
                    <span class="authors"> Carl Vondrick, Hamed Pirsiavash, Antonio Torralba.</span>
                    <span class="journal">Conference on Computer Vision and Pattern Recognition (CVPR),  2016.</span>
                </li>
            </ul>

            <ul>
                <li><a href="http://arxiv.org/abs/1512.08512">Visually Indicated Sounds.</a>
                    <span class="authors"> Andrew Owens, Phillip Isola, Josh McDermott, Antonio Torralba, Edward H. Adelson, William T. Freeman.</span>
                    <span class="journal">Conference on Computer Vision and Pattern Recognition (CVPR),  2016.</span>
                    <a class="resource" href="http://andrewowens.org/vis/index.html">Project page</a>
               </li>
            </ul>

            <ul>
                <li><a href="http://people.csail.mit.edu/khosla/papers/cvpr2016_Khosla.pdf">Eye Tracking for Everyone.</a>
                    <span class="authors">Kyle Krafka*, Aditya Khosla*, Petr Kellnhofer, Suchi Bhandarkar, Wojciech Matusik and Antonio Torralba.</span>
                    <span class="journal">Conference on Computer Vision and Pattern Recognition (CVPR),  2016.</span>
                     <a class="resource" href="http://gazecapture.csail.mit.edu/">Project page</a>
               </li>
            </ul>

            <ul>
                <li><a href="http://arxiv.org/abs/1506.06724">Visualizing Object Detection Features.</a>
                    <span class="authors">Carl Vondrick, Aditya Khosla, Hamed Pirsiavash, Tomasz Malisiewicz, Antonio Torralba.</span>
                    <span class="journal">International Journal of Computer Vision, March 2016.</span>
                    <a class="resource" href="http://web.mit.edu/vondrick/ihog/">Project page</a>
                </li>
            </ul>

            <ul>
                <li><a href="http://arxiv.org/abs/1604.03605">What do different evaluation metrics tell us about saliency models?</a>
                    <span class="authors">Zoya Bylinskii, Tilke Judd, Aude Oliva, Antonio Torralba, Fredo Durand.</span>
                    <span class="journal">Arxiv, April 2016.</span>
                </li>
            </ul>


            <ul>
                <li><a href="http://www.nature.com/articles/srep27755">Comparison of Deep Neural Networks to Spatio-temporal Cortical Dynamics of Human Visual Object Recognition reveals Hierarchical Correspondence.</a>
                    <span class="authors">Radoslaw M. Cichy, Aditya Khosla, Dimitrios Pantazis, Antonio Torralba and Aude Oliva.</span>
                    <span class="journal">Scientific Reports, 2016.</span>
                    <a class="resource" href="http://brainmodels.csail.mit.edu/">Project page</a>
               </li>
            </ul>



            <h3>2015</h3>


            <ul>
                <li><a href="http://arxiv.org/abs/1506.06724">Aligning books and movies: Towards story-like visual explanations by watching movies and reading books.</a>
                    <span class="authors">Y Zhu, R Kiros, R Zemel, R Salakhutdinov, R Urtasun, A Torralba, S Fidler.</span>
                    <span class="journal">International Conference on Computer Vision (ICCV), 2015.</span>
                    <a class="resource" href="http://www.cs.toronto.edu/~mbweb/">Project page</a>
                </li>
            </ul>


            <ul>
                <li><a href="https://groups.csail.mit.edu/vision/torralbalab/">Understanding and Predicting Image Memorability at a Large Scale.</a>
                    <span class="authors">Aditya Khosla, Akhil S. Raju, Antonio Torralba and Aude Oliva.</span>
                    <span class="journal">International Conference on Computer Vision (ICCV), 2015.</span>
                    <a class="resource" href="http://memorability.csail.mit.edu/">Project page</a>
                </li>
            </ul>


            <ul>
                <li><a href="https://groups.csail.mit.edu/vision/torralbalab/people.csail.mit.edu/khosla/papers/nips2015_recasens.pdf">Where Are They Looking?</a>
                    <span class="authors">Adrià Recasens*, Aditya Khosla*, Carl Vondrick and Antonio Torralba. ( *equal contribution).</span>
                    <span class="journal">Advances in Neural Information Processing Systems (NIPS), 2015.</span>
                    <a class="resource" href="http://gazefollow.csail.mit.edu/index.html">Project page</a> | <a class="resource" href="https://groups.csail.mit.edu/vision/torralbalab/assets/images/news/lluis_clean.avi">Video</a>
                </li>
            </ul>

            <ul>
                <li><a href="http://arxiv.org/abs/1506.06726">Skip-Thought Vectors.</a>
                    <span class="authors">Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard Zemel, Antonio Torralba, Raquel Urtasun, Sanja Fidler.</span>
                    <span class="journal">Advances in Neural Information Processing Systems (NIPS), 2015.</span>
                    <a class="resource" href="https://github.com/ryankiros/skip-thoughts">Project page</a>
                </li>
            </ul>

            <ul>
                <li><a href="http://web.mit.edu/vondrick/imagination/">Learning Visual Biases from Human Imagination.</a>
                    <span class="authors">Carl Vondrick, Hamed Pirsiavash, Aude Oliva,  and Antonio Torralba.</span>
                    <span class="journal">Advances in Neural Information Processing Systems (NIPS), 2015.</span>
                    <a class="resource" href="http://web.mit.edu/vondrick/imagination/">Project page.</a>
                </li>
            </ul>


            <ul>
                <li><a href="http://arxiv.org/pdf/1412.6856v1.pdf">Object Detectors Emerge in Deep Scene CNNs.</a>
                    <span class="authors">Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva and Antonio Torralba.</span>
                    <span class="journal">ICLR 2015.</span>
                </li>
            </ul>


            <ul>
                <li><a href="http://web.mit.edu/zoya/www/docs/figrimProof.pdf">Intrinsic and Extrinsic Effects on Image Memorability.</a>
                    <span class="authors">Bylinskii, Z., Isola, P., Bainbridge, C., Torralba, A., Oliva, A.</span>
                    <span class="journal">Vision Research 2015.</span>
                </li>
            </ul>



            <h3>2014</h3>
            <ul>
                <li><a href="http://places.csail.mit.edu/places_NIPS14.pdf">Learning Deep Features for Scene Recognition using Places Database.</a>
                    <span class="authors">B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva.</span>
                    <span class="journal">Advances in Neural Information Processing Systems 27 (NIPS), 2014.</span>
                    <a class="resource" href="http://places.csail.mit.edu/">Project page.</a> |
                    <a class="resource" href="http://places.csail.mit.edu/demo.html">Demo</a>
                </li>
               
                <li><a href="http://people.csail.mit.edu/torralba/publications/shadowsIJCV.pdf">Accidental pinhole and pinspeck cameras. Revealing the scene outside the picture.</a>
                    <span class="authors">A. Torralba, and W. T. Freeman.</span>
                    <span class="journal">International Journal of Computer Vision. November 2014, Volume 110, Issue 2, pp 92–112.</span>
                     <a class="resource" href="http://techtalks.tv/beta/talks/accidental-pinhole-and-pinspeck-cameras-revealing-the-scene-outside-the-picture/56216/">Talk</a> | <a class="resource" href="http://people.csail.mit.edu/torralba/research/accidentalcameras/">Project page</a> | <a class="resource" href="http://people.csail.mit.edu/torralba/publications/shadows.pdf">paper.pdf</a>
                </li>
                
                <li><a href="http://vision.princeton.edu/projects/2010/SUN/paperIJCV.pdf">SUN Database: Exploring a Large Collection of Scene Categories.</a>
                    <span class="authors">J Xiao, KA Ehinger, J Hays, A Torralba, A Oliva.</span>
                    <span class="journal">International Journal of Computer Vision. 2014.</span>
                    <a class="resource" href="http://groups.csail.mit.edu/vision/SUN/">Project page</a>
                </li>

                <li><a href="http://people.csail.mit.edu/khosla/papers/eccv2014_lim.pdf">FPM: Fine pose Parts-based Model with 3D CAD models.</a>
                    <span class="authors">Joseph Lim, Aditya Khosla, and Antonio Torralba.</span>
                    <span class="journal">ECCV 2014, Zurich, Switzerland.</span>
                </li>
                
                <li><a href="http://web.mit.edu/vondrick/quality.pdf">Assessing the Quality of Actions.</a>
                    <span class="authors">Hamed Pirsiavash, Carl Vondrick, and Antonio Torralba.</span>
                    <span class="journal">ECCV 2014, Zurich, Switzerland.</span>
                    <a class="resource" href="http://people.csail.mit.edu/hpirsiav/quality.html/">Project page.</a>
                </li>
                
                <li><a href="http://people.csail.mit.edu/bzhou/project/eccv2014/">Recognizing City Identity via Attribute Analysis of Geo-tagged Images.</a>
                    <span class="authors">B. Zhou, L. Liu, A. Oliva and A. Torralba.</span>
                    <span class="journal">ECCV 2014, Zurich, Switzerland.</span>
                </li>
                
                <li><a href="http://web.mit.edu/why/">Inferring the Why in Images.</a>
                    <span class="authors">Hamed Pirsiavash*, Carl Vondrick*, and Antonio Torralba. ( *equal contribution).</span>
                    <span class="journal">Tech Report.</span>
                </li>
                
                <li><a href="http://web.mit.edu/vondrick/imagination/">Acquiring Visual Classifiers from Human Imagination.</a>
                    <span class="authors">Carl Vondrick, Hamed Pirsiavash, Aude Oliva,  and Antonio Torralba.</span>
                    <span class="journal">Tech Report.</span>
                    <a class="resource" href="http://web.mit.edu/vondrick/imagination/">Project page.</a>
                </li>
            </ul>
            
            <h3>2013</h3>
            
            <ul>
                <li><a href="http://arxiv.org/pdf/1311.6510v1.pdf">Are all training examples equally valuable?</a>
                    <span class="authors">A. Lapedriza, H. Pirsiavash, Z. Bylinskii, and A. Torralba.</span>
                    <span class="journal">arXiv preprint arXiv:1311.6510, 2013.</span>
                </li>
                
                <li><a href="http://people.csail.mit.edu/torralba/publications/ihog_iccv.pdf">HOGgles: Visualizing Object Detection Features.</a>
                    <span class="authors">Carl Vondrick, Aditya Khosla, Tomasz Malisiewicz, and Antonio Torralba.</span>
                    <span class="journal">International Conference on Computer Vision (ICCV), 2013.</span>
                    <a class="resource" href="http://web.mit.edu/vondrick/ihog/">Project page.</a>
                </li>
                
                <li><a href="http://people.csail.mit.edu/torralba/publications/iccv2013_khosla.pdf">Modifying the Memorability of Face Photographs.</a>
                    <span class="authors">Aditya Khosla, Wilma A. Bainbridge, Antonio Torralba and Aude Oliva.</span>
                    <span class="journal">International Conference on Computer Vision (ICCV), 2013.</span>
                    <a class="resource" href="http://facemem.csail.mit.edu/">Project page.</a>
                </li>

                <li><a href="http://people.csail.mit.edu/torralba/publications/ikea_iccv2013.pdf">Parsing IKEA Objects: Fine Pose Estimation.</a>
                    <span class="authors">Joseph Lim, Hamed Pirsiavash, and Antonio Torralba.</span>
                    <span class="journal">International Conference on Computer Vision (ICCV), 2013.</span>
                </li>

                <li><a href="http://people.csail.mit.edu/torralba/publications/sun3d_iccv.pdf">SUN3D: A Database of Big Spaces Reconstructed using SfM and Object Labels.</a>
                    <span class="authors">Jianxiong Xiao, Andrew Owens, and Antonio Torralba.</span>
                    <span class="journal">International Conference on Computer Vision (ICCV), 2013.</span>
                    <a class="resource" href="http://sun3d.cs.princeton.edu/">Project page.</a>
                </li>

                <li><a href="http://people.csail.mit.edu/torralba/publications/anchors_iccv2013.pdf">Shape Anchors for Data-driven Multi-view Reconstruction.</a>
                    <span class="authors">Andrew Owens, Jianxiong Xiao, Antonio Torralba, and William T. Freeman.</span>
                    <span class="journal">International Conference on Computer Vision (ICCV), 2013.</span>
                </li>
                
                
                <li><a href="http://people.csail.mit.edu/torralba/publications/Isola_memorabilityPhotos_PAMI2014.pdf">What makes a photograph memorable?</a>
                    <span class="authors">Isola, P., Xiao, J., Parikh, D, Torralba, A., and Oliva, A.</span>
                    <span class="journal">IEEE Transactions on Pattern Analysis and Machine Intelligence, in press.</span>
                </li>

                
                <li><a href="http://www.cs.toronto.edu/~rsalakhu/papers/HD_PAMI.pdf">Learning with Hierarchical-Deep Models.</a>
                    <span class="authors">R. Salakhutdinov, J. B. Tenenbaum, and A. Torralba.</span>
                    <span class="journal">IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no. 8, pp. 1958-1971, Aug. 2013.</span>
                </li>
            </ul>
          
            <h3>2012</h3>
            <ul>
            <li><a href="http://people.csail.mit.edu/torralba/publications/memories.pdf">Notes on image annotation.</a>
            <span class="authors">A. Barriuso and A. Torralba.</span>
            <a href="http://arxiv.org/abs/1210.3448">arXiv:1210.3448 [cs.CV]</a> (unreferred).</li>

            <li><a href="http://mit.edu/jxiao/SUNprimitive/">Localizing 3D Cuboids in Single-view Images.</a>
            <span class="authors">J. Xiao, B. C. Russell, and A. Torralba.</span>
            <span class="journal">Advances in Neural Information Processing Systems 25 (NIPS2012).</span>
            </li>
            
            <li><a href="http://mit.edu/jxiao/Public/publication/2012/NIPSmemorability/paper.pdf">Memorability of Image Regions.</a>
            <span class="authors">A. Khosla, J. Xiao, A. Torralba and A. Oliva.</span>
            <span class="journal">Advances in Neural Information Processing Systems 25 (NIPS2012).</span>
            </li>
            
            <li><a href="http://people.csail.mit.edu/khosla/papers/eccv2012_khosla.pdf">Undoing the Damage of Dataset Bias.</a>
            <span class="authors">Aditya Khosla, Tinghui Zhou, Tomasz Malisiewicz, Alexei A. Efros, and Antonio Torralba.</span>
            <span class="journal">European Conference on Computer Vision (ECCV), 2012.</span></li>
            
            <li><a href="http://people.csail.mit.edu/torralba/publications/msh_eccv12.pdf">Multidimensional Spectral Hashing.</a>
           <span class="authors"> Y. Weiss, Rob Fergus, and Antonio Torralba.</span>
             <span class="journal">European Conference on Computer Vision (ECCV), 2012.</span></li>
            
            <li><a href="http://web.mit.edu/jxiao/Public/publication/2012/CVPR/paper.pdf">Recognizing Scene Viewpoint using Panoramic Place Representation.</a>
            <span class="authors">J. Xiao, K. A. Ehinger, A. Oliva and A. Torralba.</span>
            <span class="journal">Proceedings of 25th IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2012)</span>
            <a class="resource" href="http://sun360.mit.edu/">Project page and SUN360 database</a></li>

            <li><a href="http://people.csail.mit.edu/torralba/research/accidentalcameras/">Accidental pinhole and pinspeck cameras: revealing the scene outside the picture</a>
            <span class="authors">A. Torralba and W. T. Freeman.</span>
            <span class="journal">Proceedings of 25th IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2012)</span>
            <a class="resource" href="http://techtalks.tv/beta/talks/accidental-pinhole-and-pinspeck-cameras-revealing-the-scene-outside-the-picture/56216/">Talk</a> | <a class="resource" href="http://people.csail.mit.edu/torralba/research/accidentalcameras/">Project page</a> | <a class="resource" href="http://people.csail.mit.edu/torralba/publications/shadows.pdf">paper.pdf</a></li>
            
            <li>
            <a href="http://people.csail.mit.edu/myungjin/publications/treeContext.pdf">A Tree-Based Context Model for Object Recognition.</a><span class="authors"> Myung Jin Choi, Antonio Torralba, and Alan S. Willsky.</span> <span class="journal">IEEE Transactions on Pattern Analysis and Machine Intelligence, February 2012 (vol. 34 no. 2), pp. 240-252.</span>
            <a class="resource" href="http://people.csail.mit.edu/myungjin/HContext.html">Project page</a>
            </li>
                

            <li><a href="http://people.csail.mit.edu/myungjin/publications/outOfContext.pdf">Context Models and Out-of-context Objects.</a>
            <span class="authors">Myung Jin Choi, Antonio Torralba, and Alan S. Willsky.</span>
            <span class="journal">Pattern Recognition Letters, Volume 33, Issue 7, 1 May 2012, Pages 853-862.</span>
            <a class="resource" href="http://people.csail.mit.edu/myungjin/outOfContext.html">Project page and database of out of context objects</a>
            </li>
            </ul>
            
            
            <h3>2011</h3>
            <ul>
              <li>
               <a href="http://people.csail.mit.edu/celiu/pdfs/LabelTransferTPAMI.pdf">Nonparametric Scene Parsing via Label Transfer</a>
                <span class="authors">C. Liu, J. Yuen and A. Torralba.</span>
                <span class="journal">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), Vol 33, No. 12, 2011.</span>
               <a class="resource" href="http://people.csail.mit.edu/celiu/LabelTransfer/">Project page</a>
              </li>    
      
      
              <li>
               <a href="http://people.csail.mit.edu/lim/paper/lst_nips11.pdf">Transfer Learning by Borrowing Examples for Multiclass Object Detection</a>
                <span class="authors">J. J. Lim, R. Salakhutdinov, A. Torralba.</span>
                <span class="journal">NIPS,  2011, Granada, Spain</span>
               <a class="resource" href="http://people.csail.mit.edu/lim/lst_nips2011/index.htm">Project page</a>
              </li>    
                
              <li>
               <a href="http://web.mit.edu/phillipi/Public/UnderstandingMemorability/index.html">Understanding the intrinsic memorability of images</a>
                <span class="authors">P. Isola, D. Parikh, A. Torralba, A. Oliva.</span>
                <span class="journal">NIPS,  2011, Granada, Spain</span>
                <a class="resource" href="http://web.mit.edu/phillipi/UnderstandingMemorability/">Project page</a>
              </li>    
         
              <li>
               <a href="https://groups.csail.mit.edu/vision/torralbalab/www.utstat.toronto.edu/~rsalakhu/papers/hd.pdf">Learning to Learn with Compound Hierarchical-Deep Models</a>
                <span class="authors">R. Salakhutdinov, J. Tenenbaum , A. Torralba.</span>
                <span class="journal">NIPS,  2011, Granada, Spain</span>
              </li>    
        
              <li>
               <a href="http://people.csail.mit.edu/biliana/papers/iccv2011/iccv2011_final.pdf">Evaluation of Image Features Using a Photorealistic Virtual World</a>
                <span class="authors">B. Kaneva, A. Torralba, W.T. Freeman.</span>
                <span class="journal">ICCV,  2011, Barcelona, Spain</span>
              </li>    
        
              <li>
               <a href="http://people.csail.mit.edu/torralba/publications/WhatMakesAnImageMemorable.pdf">What makes an image memorable?</a>
                <span class="authors">P. Isola, J. Xiao, A. Torralba, A. Oliva.</span>
                <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR),  2011.</span>
                <a class="resource" href="http://web.mit.edu/phillipi/Public/WhatMakesAnImageMemorable/">Project page</a>
              </li>    
        
              <li>
               <a href="http://people.csail.mit.edu/torralba/publications/sharingCVPR2011.pdf">Learning to Share Visual Appearance for Multiclass Object Detection</a>
                <span class="authors">R. Salakhutdinov, A. Torralba, J. Tenenbaum.</span>
                <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR),  2011.</span>
              </li>    
        
              <li>
               <a href="http://people.csail.mit.edu/torralba/research/bias/">Unbiased Look at Dataset Bias</a>
                <span class="authors">A. Torralba, A. Efros.</span>
                <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR),  2011.</span>
              </li>    
        
              <li>
               <a href="https://groups.csail.mit.edu/vision/torralbalab/">A Large-scale Benchmark Dataset for Event Recognition in Surveillance Video</a>
                    <span class="authors">Sangmin Oh, Anthony Hoogs, A.G.Amitha Perera, Chia-Chih Chen, Jong Taek Lee, Jake Aggarwal, Hyungtae Lee, Larry Davis, Xiaoyang Wang, Eran Swears, Qiang Ji, Kishore Reddy, Mubarak Shah, Carl Vondrick, Hamed Pirsiavash, Deva Ramanan, Jenny Yuen, Antonio Torralba, Bi Song, Anesco Fong, Amit Roy-Chowdhury, Mita Desai.</span>
                <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR),  2011.</span>
              </li>    
        
              <li>
               <a href="http://people.csail.mit.edu/tjudd/LowRes/LowResolutionPaper.pdf">Fixations on Low-Resolution Images</a>
                <span class="authors">T. Judd, F. Durand, A. Torralba.</span>
                <span class="journal">Journal of Vision, April 25, 2011 vol. 11 no. 4 article 14.</span>
                <a class="resource" href="http://people.csail.mit.edu/tjudd/LowRes/index.html">Project page</a> |
                <a class="resource" href="http://people.csail.mit.edu/tjudd/LowRes/seeFixations.html">Play fixations</a>
              </li>    
        
              <li>
               <a href="http://cvcl.mit.edu/papers/Ehinger-SUNtypicality-submitted.pdf">Estimating scene typicality from human ratings and image features</a>
                <span class="authors">K. A. Ehinger, J. Xiao, A. Torralba and A. Oliva.</span>
                <span class="journal">Proceedings of the 33rd Annual Conference of the Cognitive Science Society, Boston, MA: Cognitive Science Society 2011, in press.</span>
              </li>    
        
              <li>
               <a href="http://people.csail.mit.edu/celiu/SIFTflow/SIFTflow.pdf">SIFT Flow: Dense Correspondence across Scenes and Its Applications</a>
                <span class="authors">Ce Liu, Jenny Yuen, Antonio Torralba.</span>
                <span class="journal">IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 33, no. 5, pp. 978-994, May 2011.</span>
                <a class="resource" href="http://people.csail.mit.edu/celiu/SIFTflow">Project page</a>
              </li>    
      
              <li>
               <a href="http://www.perceptionweb.com/abstract.cgi?id=p6762">How little do we need for 3-D shape perception?</a>
                <span class="authors">Nandakumar C., Torralba A., Malik J.</span>
                <span class="journal">Perception 40(3) 257 – 271, 2011.</span>
              </li>    
          </ul>
          
          <h3>2010</h3>
          <ul>
          <li>
             <a href="http://people.csail.mit.edu/torralba/publications/evt_pred_eccv2010.pdf">A data-driven approach for event prediction</a>
              <span class="authors">Jenny Yuen, Antonio Torralba.</span>
              <span class="journal">European Conference on Computer Vision (ECCV), 2010. </span>
            </li>    
      
            <li>
             <a href="http://people.csail.mit.edu/torralba/publications/eccv10_ssl.pdf">Semantic Label Sharing for Learning with Many Categories</a>
              <span class="authors">Rob Fergus, Hector Bernal, Yair Weiss, Antonio Torralba.</span>
              <span class="journal">European Conference on Computer Vision (ECCV), 2010. </span>
            </li>    
      
            <li>
             <a href="http://www.cs.cmu.edu/~gunhee/r_dynamic.html">Modeling and Analysis of Dynamic Behaviors of Web Image Collections</a>
             <span class="authors"> K. Gunhee, E. Xing, A. Torralba.</span>
              <span class="journal">European Conference on Computer Vision (ECCV), 2010. </span>
              <a class="resource" href="http://www.cs.cmu.edu/~gunhee/r_dynamic.html">Project page</a>
            </li>    
              
            <li>
             <a href="http://people.csail.mit.edu/biliana/papers/eccv2010/eccv_workshop_2010.pdf">Matching and Predicting Street Level Images</a>
              <span class="authors">B. Kaneva, J. Sivic, A. Torralba, S. Avidan, W. T. Freeman.</span>
              <span class="journal">Workshop for Vision on Cognitive Tasks, ECCV 2010.</span>
            </li>    
                      
            <li>
             <a href="http://people.csail.mit.edu/torralba/publications/hcontext.pdf">Exploiting Hierarchical Context on a Large Database of Object Categories</a>
              <span class="authors">Myung Jin Choi, Joseph Lim, Antonio Torralba, and Alan S. Willsky.</span>
              <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), San Francisco, CA, June 2010. </span>
        <a class="resource" href="http://web.mit.edu/~myungjin/www/HContext.html">SUN Database, object annotations and precomputed detectors</a>
            </li>      
      
            <li>
             <a href="http://web.mit.edu/jxiao/Public/publication/2010/CVPR_sun/paper.pdf">SUN Database: Large Scale Scene Recognition from Abbey to Zoo</a>
              <span class="authors">J. Xiao, J. Hays, K. Ehinger, A. Oliva, and  A. Torralba.</span>
              <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), San Francisco, CA, June 2010. </span>
       <a class="resource" href="http://groups.csail.mit.edu/vision/SUN/">SUN Database, scene recognition benchmark</a>
            </li>      
      
            <li>
             <a href="https://groups.csail.mit.edu/vision/torralbalab/">Part and Appearance Sharing: Recursive Compositional Models for Multi-View Multi-Object Detection</a>
              <span class="authors">Leo Zhu, Yuanhao Chen, Antonio Torralba, William Freeman, and Alan Yuille.</span>
              <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), San Francisco, CA, June 2010. </span>
            </li>      
      
            <li>
             <a href="http://cacm.acm.org/magazines/2010/3/76274-using-the-forest-to-see-the-trees/comments">Using the forest to see the trees: object recognition in context</a>
              <span class="authors">A. Torralba, K. Murphy, W. T. Freeman.</span>
              <span class="journal">Communications of the ACM, Research Highlights, 53(3): 107-114, 2010. </span>
            </li>      
      
            <li>
             <a href="http://people.csail.mit.edu/torralba/publications/labelmeApplications.pdf">LabelMe: online image annotation and applications</a>
              <span class="authors">A. Torralba, B. C. Russell, J. Yuen.</span>
              <span class="journal">Proceedings of the IEEE, Vol. 98, n. 8, pp. 1467 – 1484, August 2010. </span>
            </li>      
      
            <li>
             <a href="http://people.csail.mit.edu/biliana/papers/pieee2009/pieee2009.pdf">Infinite Images: Creating and Exploring a Large Photorealistic Virtual Space</a>
              <span class="authors">B. Kaneva, J. Sivic, A. Torralba, S. Avidan, W. T. Freeman.</span>
              <span class="journal">Proceedings of the IEEE, Vol. 98, n. 8, pp. 1391-1407, August 2010. </span>
            </li>   
        </ul>
        
        
        <h3>2009</h3>
        <ul>
          <li><a href="http://cs.nyu.edu/~fergus/papers/fwt_ssl.pdf">Semi-supervised Learning in Gigantic Image Collections</a>
            <span class="authors">R. Fergus, Y. Weiss, and A. Torralba.</span>
            <span class="journal">Advances in Neural Information Processing Systems, 2009. </span>
          </li>      
          
          <li><a href="http://www.cs.cmu.edu/~gunhee/publish/nips09_gunhee.pdf">Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</a>
            <span class="authors">G. Kim, and A. Torralba.</span>
            <span class="journal">Advances in Neural Information Processing Systems, 2009. </span>
            <a class="resource" href="http://www.cs.cmu.edu/~gunhee/r_roi.html">Project page</a>
          </li>      
          
          <li><a href="http://people.csail.mit.edu/billf/papers/texturelearning09.pdf">Nonparametric Bayesian Texture Learning and Synthesis</a>
            <span class="authors">Long Zhu, Yuanhao Chen, William Freeman, and Antonio Torralba.</span>
            <span class="journal">Advances in Neural Information Processing Systems, 2009. </span>
          </li>      
          
       
          <li><a href="http://www.di.ens.fr/~russell/papers/LabelMeVideo.pdf">LabelMe video: building a video database with human annotations</a>
            <span class="authors">J. Yuen, B. C. Russell, C. Liu, and A. Torralba.</span>
            <span class="journal">IEEE International Conference on Computer Vision (ICCV), 2009. </span>
          </li>     
           
          <li><a href="http://people.csail.mit.edu/torralba/publications/wherepeoplelook.pdf">Learning to predict where humans look</a>
            <span class="authors">T. Judd, K. Ehinger, F. Durand, and A. Torralba.</span>
            <span class="journal">IEEE International Conference on Computer Vision (ICCV), 2009.</span>
          <a class="resource" href="http://people.csail.mit.edu/tjudd/WherePeopleLook/index.html">Project page</a>      
          </li>
          
          <li><a href="http://people.csail.mit.edu/torralba/publications/siftFlowCVPR.pdf">Nonparametric scene parsing: label transfer via dense scene alignment</a>
            <span class="authors">C. Liu, J. Yuen, A. Torralba.</span>
            <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2009. </span>
          </li>
          
          <li><a href="http://web.mit.edu/torralba/www/indoor.html">Recognizing indoor scenes</a>
            <span class="authors">A. Quattoni, and A. Torralba.</span>
            <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2009. </span>
          </li>
    
          <li><a href="http://people.csail.mit.edu/torralba/publications/LabelMe3D.pdf">Building a database of 3D scenes from user annotations</a>
            <span class="authors">B. C. Russell and A. Torralba.</span>
            <span class="journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2009. </span>
            <a class="resource" href="http://labelme2.csail.mit.edu/Release3.0/browserTools/php/labelme3d_toolbox.php"> Project website</a> 
         </li>
    
          <li>
            <a href="http://cvcl.mit.edu/abstracts/MultiSourceGuidance.html">Modelling search for people in 900 scenes: a combined source model of eye guidance</a>
            <span class="authors">K. Ehinger, B. Hidalgo-Sotelo, A. Torralba, and A. Oliva.</span>
            <span class="journal">Visual Cognition, Vol. 17, Issue 6 &amp; 7 August 2009 , pages 945 - 978, 2009.</span>
            <a class="resource" href="http://cvcl.mit.edu/searchmodels">Project page</a>
           </li>
            
          <li><a href="http://journals.cambridge.org/repo_A51P7pMw">How many pixels make an image?</a>
           <span class="authors"> A. Torralba.</span>
            <span class="journal">Visual Neuroscience, volume 26, issue 01, pp. 123-131, 2009.</span>
          </li>
         </ul> 
         
         
         <h3>2008</h3>
         <ul>
           <li> 
             <a href="http://people.csail.mit.edu/torralba/publications/spectralhashing.pdf">Spectral Hashing</a>
              <span class="authors">Y. Weiss, A. Torralba, R. Fergus.</span>
              <span class="journal">Advances in Neural Information Processing Systems, 2008.</span>
              <a class="resource" href="http://www.cs.huji.ac.il/~yweiss/SpectralHashing/">Project page</a> 
              | <a class="resource" href="http://people.csail.mit.edu/torralba/research/spectralHashing/LabelMe_NIPS_2008.mat"> LabelMe data and GIST</a> 
            </li>
              
              
            <li><a href="http://people.csail.mit.edu/celiu/pdfs/SIFTflow.pdf">SIFT flow: dense correspondence across different scenes</a>
             <span class="authors"> C. Liu, J. Yuen, A. Torralba, J. Sivic, and W. T. Freeman.</span>
              <span class="journal">European Conference on Computer Vision (ECCV), 2008.</span>
              <a class="resource" href="http://people.csail.mit.edu/celiu/ECCV2008/">Project page</a> 
            </li>
            <li> <a href="http://people.csail.mit.edu/torralba/publications/cvpr2008.pdf">Small codes and large databases for recognition</a>
              <span class="authors">A. Torralba, R. Fergus, Y. Weiss.</span>
              <span class="journal">IEEE Computer Vision and Pattern Recognition, June 2008.</span>
              <a class="resource" href="http://people.csail.mit.edu/torralba/tinyimages/"> Project page</a> 
              | <a class="resource" href="http://cs.nyu.edu/~fergus/research/tfw_cvpr08_code.zip">code</a> 
            </li>
            <li><a href="http://www.di.ens.fr/~josef/publications/sivic08a.pdf">Creating and exploring a large photorealistic virtual space</a>
              <span class="authors">J. Sivic, B. Kaneva, A. Torralba, S. Avidan and W. T. Freeman.</span>
              <span class="journal">First IEEE Workshop on Internet Vision, associated with CVPR 2008. </span>
             </li>
            <li> <a href="http://people.csail.mit.edu/torralba/publications/80millionImages.pdf"> 80 million tiny images: a large dataset for non-parametric object and scene recognition</a>
              <span class="authors">A. Torralba, R. Fergus, W. T. Freeman.</span>
              <span class="journal">IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.30(11), pp. 1958-1970, 2008.</span>
              <a class="resource" href="http://www.di.ens.fr/~russell/projects/recognitionBySceneAlignment/index.html">Project page</a>
             </li>
            <li><a href="http://ssg.mit.edu/~esuddert/papers/ijcv07.pdf">Describing Visual Scenes Using Transformed Objects and Parts</a>
             <span class="authors"> E. Sudderth, A. Torralba, W. T. Freeman, and A. Willsky.</span>
              <span class="journal">International Journal of Computer Vision, No. 1-3, May 2008, pp. 291-330.</span>
              <a class="resource" href="http://www.cs.berkeley.edu/~sudderth/software.html#tdp">Project page</a> </li>
            <li> <a class="resource" href="http://people.csail.mit.edu/brussell/research/AIM-2005-025-new.pdf">  LabelMe: a database and web-based tool for image annotation</a>
              <span class="authors">B. Russell, A. Torralba, K. Murphy, W. T. Freeman.</span>
              <span class="journal">International Journal of Computer Vision, pages 157-173, Volume 77, Numbers 1-3, May, 2008.</span>
              <a class="resource" href="http://labelme.csail.mit.edu/">Project page</a>
             </li>
             
          </ul>
         
         <h3>2007</h3>
         <ul>
          <li><a href="http://people.csail.mit.edu/torralba/publications/sharing.pdf">Sharing visual features for multiclass and multiview object detection</a>
            <span class="authors">A. Torralba, K. P. Murphy and W. T. Freeman.</span>
            <span class="journal">IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 29, no. 5, pp. 854-869, May, 2007.</span>
            <a class="resource" href="http://people.csail.mit.edu/torralba/code/sharing/sharing.zip">Code</a> 
          </li>
          <li><a href="http://cvcl.mit.edu/Papers/OlivaTorralbaTICS2007.pdf">The role of context in object recognition</a>
            <span class="authors">A. Oliva, A. Torralba.</span>
            <span class="journal">Trends in Cognitive Sciences, vol. 11(12), pp. 520-527. December 2007.</span>
          </li>
          <li><a href="http://people.csail.mit.edu/torralba/publications/nipsRecognitionBySceneAlignment.pdf">Object Recognition by Scene Alignment</a>
            <span class="authors">B. C. Russell, A. Torralba, C. Liu, R. Fergus, W. T. Freeman.</span>
            <span class="journal">Advances in Neural Information Processing Systems, 2007.</span>
            <a class="resource" href="http://bryanrussell.org/projects/recognitionBySceneAlignment/index.html">Project page</a> 
           </li>
        </ul>
        
        <h3>2006</h3>
        <ul>
         <li>
           <a href="http://people.csail.mit.edu/torralba/publications/torralbaEyeMovements.pdf">Contextual Guidance of Attention in Natural scenes: The role of Global features on object search</a>
           <span class="authors"> A. Torralba, A. Oliva, M. Castelhano and J. M. Henderson.</span>
            <span class="journal">Psychological Review. Vol 113(4) 766-786, Oct, 2006.</span>
            <a class="resource" href="http://people.csail.mit.edu/torralba/GlobalFeaturesAndAttention/">Project page</a> 
         </li>
         <li><a href="http://ssg.mit.edu/~esuddert/papers/cvpr06.pdf">Depth from Familiar Objects: A Hierarchical Model for 3D Scenes</a>
            <span class="authors"> E. Sudderth, A. Torralba, W. T. Freeman, and A. Willsky.</span>
            <span class="journal">CVPR, June 2006.</span>
            <a class="resource" href="http://labelme.csail.mit.edu/browseLabelMe/seq_stereo_office_stata_oct24.html">Dataset</a> 
          </li>
         <li><a href="http://cvcl.mit.edu/gallery.htm">Hybrid images</a>
          <span class="authors"> A. Oliva, A. Torralba and P. Schyns.</span>
          <span class="journal">ACM Transactions on Graphics, ACM Siggraph, 25-3, pp. 527-530. 2006. </span>
          </li>
         <li> <a href="http://dspace.mit.edu/bitstream/1721.1/33962/2/MIT-CSAIL-TR-2006-058.pdf"> Random Lens Imaging</a>
         <span class="authors">  R. Fergus, A. Torralba, W. T. Freeman.</span>
          <span class="journal">MIT CSAIL Technical Report 2006-058, 2006.</span>
         </li>
        <li><a href="http://cvcl.mit.edu/Papers/OlivaTorralbaPBR2006.pdf">Building the Gist of a Scene: The Role of Global Image Features in Recognition</a>
         <span class="authors">  A. Oliva, and A. Torralba.</span>
          <span class="journal">Visual Perception, Progress in Brain Research, vol 155. 2006. </span>
          </li>
        <li><a href="http://www-cvr.ai.uiuc.edu/ponce_grp/publication/paper/sicily06c.pdf">Dataset Issues in Object Recognition</a>
          <span class="authors"> J. Ponce, T. L. Berg, M. Everingham, D. A. Forsyth, M. Hebert, S. Lazebnik, M. Marszalek, C. Schmid, B. C. Russell, A. Torralba, C. K. I. Williams, J. Zhang, and A. Zisserman.</span>
          <span class="journal">In Toward Category-Level Object Recognition. Springer-Verlag Lecture Notes in Computer Science, J. Ponce, M. Hebert, C. Schmid, and A. Zisserman (eds.), 2006. </span>
          </li>
        <li><a href="http://people.csail.mit.edu/torralba/publications/localAndGlobal.pdf">Object detection and localization using local and global features</a>
          <span class="authors"> K. Murphy, A. Torralba, D. Eaton, W. T. Freeman.</span>
          <span class="journal">In Toward Category-Level Object Recognition. Springer-Verlag Lecture Notes in Computer Science, J. Ponce, M. Hebert, C. Schmid, and A. Zisserman (eds.), 2006.</span>
          </li>
        <li><a href="https://groups.csail.mit.edu/vision/torralbalab/sicilyChapterSharing.pdf">Shared features for multiclass object detection</a>
          <span class="authors"> A. Torralba, K. P. Murphy, W. T. Freeman.</span>
          <span class="journal">In Toward Category-Level Object Recognition. Springer-Verlag Lecture Notes in Computer Science, J. Ponce, M. Hebert, C. Schmid, and A. Zisserman (eds.), 2006.</span>
         </li>      
      </ul>
      
      
      <h3>2005</h3>
      <ul>
      <li> 
          <a href="ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-013.pdf">Contextual Models for Object Detection using Boosted Random Fields</a>
          <span class="authors">A. Torralba, K. P. Murphy and W. T. Freeman.</span>
         <span class="journal"> Adv. in Neural Information Processing Systems 17 (NIPS), pp. 1401-1408, 2005.</span>
          <a class="resource" href="https://groups.csail.mit.edu/vision/torralbalab/bib/NIPS2005_704.txt">bibtex</a> 
        </li>
    <li><a href="http://ssg.mit.edu/~esuddert/papers/nips05.pdf">Describing Visual Scenes using Transformed Dirichlet Processes</a>
          <span class="authors">E. Sudderth, A. Torralba, W. T. Freeman, and A. Willsky.</span>
           <span class="journal">NIPS 2005. </span>
        </li>
        <li> <a href="http://ssg.mit.edu/~esuddert/papers/iccv05.pdf"> Learning Hierarchical Models of Scenes, Objects, and Parts</a>
         <span class="authors"> E. Sudderth, A. Torralba, W. T. Freeman, and A. Willsky.</span>
           <span class="journal">ICCV 2005. </span>
          </li>
        <li><a href="http://people.csail.mit.edu/~celiu/motionmag/motionmag.html">Motion magnification</a>
         <span class="authors"> C. Liu, A. Torralba, W.T. Freeman, F. Durand and E.H. Adelson.</span>
          <span class="journal"> ACM Trans. on Graphics, ACM Siggraph, 24-3, pp. 519-526, 2005.</span>
          </li>
        <li><a href="http://people.csail.mit.edu/torralba/publications/WAPCV2005.pdf">Human Learning of Contextual Priors for Object Search: Where does the time go?</a>
         <span class="authors"> B. Hidalgo-Sotelo, A. Oliva, and A. Torralba.</span>
           <span class="journal">Proceedings of the 3rd Workshop on Attention and Performance in Computer Vision at the Int. CVPR, 2005. </span>
         </li>
        <li> <a href="ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-009.pdf">Contextual Influences on Saliency</a>
          <span class="authors">A. Torralba</span>
           <span class="journal">Neurobiology of Attention, Eds. L. Itti, G. Rees and J. Tsotsos. Pages 586-593. Academic Press / Elsevier. 2005</span>
         </li>
         <li>An Ensemble Prior of Image Structure for Cross-modal Inference
          <span class="authors">S. Ravela, A. Torralba, W. T. Freeman.</span>
          <span class="journal"> ICCV 2005 </span>
         </li>
       </ul>
       
       <h3>2004</h3>
       <ul>
       <li> <a href="http://web.mit.edu/torralba/www/ne3302.pdf"> </a><a href="http://web.mit.edu/torralba/www/cvpr2004.pdf">Sharing features: efficient boosting procedures for multiclass 
         object detection</a>
        <span class="authors">A. Torralba, K. P. Murphy and W. T. Freeman.</span>
        <span class="journal">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR). pp 762-769, 2004. </span>
        </li>
        <li><a href="http://www.journalofvision.org/4/9/10/">Specular reflections and the perception of shape</a>
          <span class="authors">R. W. Fleming, A. Torralba and E. H. Adelson.</span>
          <span class="journal">Journal of Vision. Volume 4, Number 9, Article 10, Pages 798-820. 2004. </span>
        </li>
        <li><a href="http://eyelab.msu.edu/people/monica/Torralba%20et%20al.%20VSS04.pdf">Saliency, objects and scenes: global scene factors in attention and object detection</a>
         <span class="authors"> A. Torralba, A. Oliva, M. Castelhano and J. M. Henderson.</span>
        <span class="journal">Vision Sciences Society Annual Meeting, Sarasota. 2004.</span>
         </li>
      </ul>
    
    <h3>2003</h3>
        <ul>
          <li>
          <a href="http://web.mit.edu/torralba/www/ne3302.pdf">Statistics of natural image categories</a>
             <span class="authors"> A. Torralba and A. Oliva.</span>
              <span class="journal">Network: computation in neural systems, Vol. 14, 391-412. 2003.</span>
           </li>
            <li> <a href="http://cvcl.mit.edu/Papers/Torralba-Oliva02.pdf"> Depth estimation from image structure</a>
             <span class="authors">  A. Torralba, A. Oliva.</span>
              <span class="journal">IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 24(9): 1226-1238. 2003. </span>
              </li>
            <li><a href="http://www.ai.mit.edu/people/torralba/IJCVobj.pdf">Contextual priming for object detection</a>
              <span class="authors"> A. Torralba.</span>
             <span class="journal"> International Journal of Computer Vision, Vol. 53(2), 169-191, 2003. </span>
              </li>
            <li> <a href="ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-005.pdf"> Context-based vision system for place and object recognition</a>
              <span class="authors"> A. Torralba, K. P. Murphy, W. T. Freeman and M. A. Rubin.</span>
             <span class="journal"> IEEE Intl. Conference on Computer Vision (ICCV), Nice, France, October 2003.</span>
              <a class="resource" href="http://people.csail.mit.edu/torralba/images/"> Code and datasets</a> 
              </li>
            <li> <a href="http://web.mit.edu/torralba/www/nips2003.pdf"> Using the forest to see the trees: a graphical model relating features, objects and scenes</a>
              <span class="authors"> P. Murphy, A. Torralba and W. T. Freeman.</span>
             <span class="journal"> Adv. in Neural Information Processing Systems 16 (NIPS), Vancouver, BC, MIT Press, 2003. </span>
              </li>
            <li>
              <a href="http://web.mit.edu/torralba/www/josa.pdf">Modeling global scene factors in attention</a>
             <span class="authors">  A. Torralba.</span>
             <span class="journal"> Journal of Optical Society of America. A Special Issue on Bayesian and Statistical Approaches to Vision. Vol. 20(7): 1407-1418, 2003.</span>
            </li>
      
            <li> <a href="http://web.mit.edu/torralba/www/ICIP03.pdf"> Top-down control of visual attention in object detection</a>
              <span class="authors"> A. Oliva, A. Torralba, M. S. Castelhano and J. M. Henderson.</span>
              <span class="journal">Proceedings of the IEEE International Conference on Image Processing. Vol. I, pages 253-256; September 14-17, in Barcelona, Spain, 2003. </span>
              </li>
            <li> <a href="ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-019.pdf">Properties and applications of shape recipes</a>
              <span class="authors"> A. Torralba and W. T. Freeman.</span>
              <span class="journal">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), Madison, WI, June, 2003. </span>
             </li>
      
          </ul>
            
          <h3>2002</h3>
          <ul>
            <li><a href="http://people.csail.mit.edu/torralba/publications/BMVCscenedescription.pdf">Scene-Centered Description from Spatial Envelope Properties</a>
              <span class="authors">A. Oliva, A. Torralba.</span>
              <span class="journal">In Proc. 2nd Workshop on Biologically Motivated Computer Vision (BMCV'02),Tubingen, Germany. 2002.</span> 
              </li>
            <li><a href="http://people.csail.mit.edu/torralba/publications/shapeRecipesNIPS.pdf">Shape Recipes: Scene Representations that Refer to the Image</a>
              <span class="authors">W. T. Freeman, A. Torralba.</span>
              <span class="journal">Adv. in Neural Information Processing Systems 15 (NIPS), MIT Press. </span>
              </li>
      </ul>
         
         <h3>2001</h3>
         <ul>
             
             
          <li> 
          <a href="http://people.csail.mit.edu/torralba/publications/contextModulationNIPS.pdf">Contextual modulation of target saliency</a>
            <span class="authors">A. Torralba.</span>
            <span class="journal">Adv. in Neural Information Processing Systems 14 (NIPS), MIT Press, 2001. </span>
          </li>
             
             
          <li> <a href="http://web.mit.edu/torralba/www/iccv2001.pdf"> Statistical context priming for object detection</a>
            <span class="authors">A. Torralba, P. Sinha.</span>
             <span class="journal">Proceedings of the International Conference on Computer Vision (ICCV), pp. 763-770, Vancouver, Canada, 2001. </span>
          </li>
                        
             
          <li>
          <a href="http://cvcl.mit.edu/Papers/IJCV01-Oliva-Torralba.pdf">Modeling the shape of the scene: a holistic representation of the spatial envelope</a>
            <span class="authors">A. Oliva, A. Torralba.</span>
             <span class="journal">International Journal of Computer Vision, Vol. 42(3): 145-175, 2001.</span>
            <a class="resource" href="http://people.csail.mit.edu/torralba/code/spatialenvelope/">Code</a> 
            | <a class="resource" href="http://cvcl.mit.edu/database.htm"> Datasets</a> | <a class="resource" href="http://labelme.csail.mit.edu/browseLabelMe/spatial_envelope_256x256_static_8outdoorcategories.html">  LabelMe</a>         
          </li>
             
          <li> Global depth perception from familiar scene structure
            <span class="authors">A. Torralba, A. Oliva.</span>
             <span class="journal">AI-Memo 2001-036, CBCL Memo 213, 2001.</span>
          </li>
             
          <li>Indoor scene recognition
           <span class="authors"> A. Torralba, P. Sinha.</span>
             <span class="journal">AI Memo 2001-015, CBCL Memo 202, 2001 </span>
          </li>
          <li><a href="https://groups.csail.mit.edu/vision/torralbalab/AIM-2001-028.pdf">Detecting faces in impoverished images</a>
            <span class="authors">A. Torralba, P. Sinha.</span>
            <span class="journal"> AI Memo 2001-028, CBCL Memo 208, 2001. </span>
          </li>
          <li><a href="http://www.kyb.mpg.de/~roland">Shape from sheen. Three dimensional shape perception</a>
            <span class="authors">R. W. Fleming, A. Torralba, and E. H. Adelson.</span>
             <span class="journal">(Eds.) Zaidi, Q., Springer </span>
         </li>
        <li> An efficient neuromorphic analog network for motion estimation
           <span class="authors"> A. Torralba, J. Hérault.</span>
             <span class="journal">IEEE Transactions on Circuits and Systems-I. Special Issue on Bio-Inspired Processors and CNNs for Vision. Vol. 46(2): 269-280, 1999. </span>
            </li>
          <li>Semantic organization of scenes using discriminant structural templates
            <span class="authors">A. Torralba, A. Oliva</span>
             <span class="journal">Proceedings of the International Conference on Computer Vision, pp. 1253-1258, Korfu, Grece, 1999. </span>
            </li>
        </ul>


        </div>
     <!----------------------------------GALLERY ------------------------------------- -->
    
         <div id="gallery" class="thumbs-section">
            <h2>Gallery</h2>
<p>Here there are some art projects I like expending time on. Most of them are inspired by some of our research projects.</p>

            <p><img src="./Antonio Torralba_files/world_2_pannels.jpg" width="300" height="256">
                <span class="gallery-title">Average World</span> - <span class="title-date">2014 - 2020</span><br>
                2 panels clay 60 x 121 cm each, images mounted on wooden cubes 1.9cm
                <br><br>
                Images are averaged according to GPS locations. Each cell contains the average of 150 images taken at that location. Images come from Flickr. Each average shows the colors typical of that region of the world. We can appreciate the green regions in south america, red in the Sahara, ...
                Each average image is mounted on a wooden cube 1.9cm and attached to a clay panel. The final map will have 4 pannels and more than 3000 cubes. I am working on the third pannel ...  
                <br><br>
                <img src="./Antonio Torralba_files/cube.jpeg" width="64" height="256"> 
                <img src="./Antonio Torralba_files/detail_map.jpg" width="64" height="256">
                <img src="./Antonio Torralba_files/world.jpg" width="128" height="256">
            </p>

<p><br></p>

            <p><img src="./Antonio Torralba_files/periodic_table.jpg" width="300" height="256">
                <span class="gallery-title">Periodic Table</span> - <span class="title-date">2018</span><br>
                Images mounted on wooden cubes 1.9cm
                <br><br>
                Each image shows the average of the images download from a Google query with the name of each element in the periodic table. The name of the element appears in the average because some of the returned images contain the element symbols. Many of the colors are close to the actual color of the element. Some of the heaviest elements have never been photographied, so this is a fun Google-prediction of how they might look. Each image is mounted on a wooden cube 1.9cm.
            </p>

<p><br></p>

            <p><img src="./Antonio Torralba_files/wordnet.jpg" width="300" height="256">
                <span class="gallery-title">Visual Dictionary</span> - <span class="title-date">2008</span><br>
                Each of the tiles in the mosaic is an arithmetic average of images relating to one of 53,464 nouns. Words are placed in the array using the wordnet hierarchy (nearby tiles correspond to similar concepts). The images for each word were obtained using Google’s Image Search and other engines. Each tile is the average of 140 images. The average reveals the dominant visual characteristics of each word. For some, the average turns out to be a recognizable image; for others the average is a colored blob.
            </p>

<p><br></p>

        
            <p>
                <img src="./Antonio Torralba_files/pedraza_small.jpg" width="300" height="256">
                <span class="gallery-title">Accidental image in Pedraza, Spain</span> - <span class="title-date">2013</span><br>
                
                Picture of a bedroom processed by Retinex to enhance the illumination component.  The enhanced illumination image has a strong chromatic component. The illumination image is produced by light entering by a window on the opposite wall (not visible in the photograph). Therefore, it is an upside-down image of the scene outside the window and it clearly shows the blue of the sky, and the green patch of the grass on the ground outside the window. 
                <br><br>
                <img src="./Antonio Torralba_files/pedraza_room.jpg" width="86" height="256"> 
                <img src="./Antonio Torralba_files/pedraza_outdoor_small.jpg" width="64" height="256">
            </p>

<p><br></p>

        
            <p>
                <img src="./Antonio Torralba_files/image1.jpg" width="146" height="256">
                <img src="./Antonio Torralba_files/image2.jpg" width="146" height="256">
                <span class="gallery-title">Noise or Texture</span> - <span class="title-date">2013</span><br>             
                Where is the noise, in the image or in the world? The left image is corrupted by additive noise. We do not perceive this scene as being composed by objects covered with a strange form of paint. Instead, we see that there is noise and it is not supposed to be there. In the second image, we do not perceive the random texture as being noise despite the strong similarities with the first image.
            </p>

<p><br></p>

            <p>
                <img src="./Antonio Torralba_files/blob_personalities.jpg" width="300" height="256">
                <span class="gallery-title">Multiple blob personalities</span> - <span class="title-date">2008</span><br>             
                In presence of image degradation (e.g. blur), object recognition is strongly influenced by contextual information. Recognition makes assumptions regarding object identities based on its size and location in the scene.
            </p>

<p><br></p>

            <p><img src="./Antonio Torralba_files/boatSmooth2048_crop1_small.jpg" width="300" height="256">
                <span class="gallery-title">Sailboat in Charles River (fall)</span> - <span class="title-date">2005</span><br>
                Pictures are aligned on one sailboat. All the pictures contain the same sailboat taken within a few minutes apart.
            </p>

<p><br></p>

            <p><img src="./Antonio Torralba_files/tableau.jpg" width="300" height="256">
                <span class="gallery-title">Sailboats in Charles river (spring)</span> - <span class="title-date">2005</span><br>
                This superposition contains multiple sailboats. All the images are shifted and scaled so that the boats are roughly aligned.
            </p>

<p><br></p>

                        <p><img src="./Antonio Torralba_files/averages100objects.jpg" width="300" height="256">
                <span class="gallery-title">Average Caltech 101</span> - <span class="title-date">2003</span><br>
                Average of 100 of the objects from the Caltech-101 dataset.
            </p>
<p><br></p>

            <p><img src="./Antonio Torralba_files/averageInCambridge.jpg" width="300" height="256">
                <span class="gallery-title">Average of people in Cambridge</span> - <span class="title-date">
                2003</span><br>
            

Average images are created by adding together many pictures. 
<!--If the pictures being averaged contain some commonalities, a pattern emerges revealing the regularities existing in the intensity patterns across all the images. For instance, by averaging hundreds of images aligned on frontal faces, a common pattern of intensities emerges, showing a rigid organization of facial parts shared by all the members of the ‘face’ category.--> Image averaging has been used by artists such as <a href="http://www.salavon.com/work/category/amalgamations/">Jason Savalon</a>, <a href="http://www.jimcampbell.tv/portfolio/still_image_works/dynamisms/index.html">Jim Campbell</a> among several other artists. I used average images to motivate the study of context models in computer vision and to illustrate that the influence of an object in an image extends beyond its boundaries. Before averaging, each picture is translated and scaled so that a particular object is in the center of the picture. Average images aligned on a single object that occupies a small portion of the picture can reveal additional regions beyond the boundaries of the object that provide meaningful contextual structure for supporting it. </p>

<!--For instance, a monitor and table emerge in the background of the average keyboard despite the fact that the images were not constrained to contain those other objects. The background of the fire hydrant is less distinct, but, because it must be supported on the ground, the average image reveals a ground plane. The presence of a particular object constrains the identity and location of nearby objects</p> -->


<p><br></p>

            <p>
                <img src="./Antonio Torralba_files/normal.jpg" width="147" height="256">
                <img src="./Antonio Torralba_files/pose.jpg" width="147" height="256">
                <span class="gallery-title">Car and pedestrian</span> - <span class="title-date">2001</span><br>
                In presence of image degradation (e.g. blur), object recognition is strongly influenced by contextual information. Recognition makes assumptions regarding object identities based on its size and location in the scene. In this picture subjects describe the scenes as (left) a car in the street, and (right) a pedestrian in the street. However, the pedestrian is in fact the same shape as the car except for a 90 degrees rotation. The non-typicality of this orientation for a car within the context defined by the street scene makes the car be perceived as a pedestrian. Without degradation, subjects can correctly recognize the rotated car due to the sufficiency of local features.
            </p>


           
        <p></p>
        </div>
               


    <!-- Site Meter 
    <script type="text/javascript" src="http://s25.sitemeter.com/js/counter.js?site=s25homepageat">
        </script>
    <noscript>
        <a href="http://s25.sitemeter.com/stats.asp?site=s25homepageat" target="_top">
            <img src="http://s25.sitemeter.com/meter.asp?site=s25homepageat" alt="Site Meter" border="0"/></a>
    </noscript>
    Copyright (c)2006 Site Meter -->


      <!--##############################################-->


  <!-- Bootstrap core JavaScript -->
  <script src="./Antonio Torralba_files/jquery.min.js.下载"></script>
  <script src="./Antonio Torralba_files/bootstrap.bundle.min.js.下载"></script>

  <!-- Plugin JavaScript -->
  <script src="./Antonio Torralba_files/jquery.easing.min.js.下载"></script>

  <!-- Custom JavaScript for this theme -->
  <script src="./Antonio Torralba_files/scrolling-nav.js.下载"></script>




</div></body></html>